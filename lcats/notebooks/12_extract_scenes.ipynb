{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427d9f4f",
   "metadata": {},
   "source": [
    "# Analyze Corpus, Reloaded\n",
    "\n",
    "This notebook analyzes our corpus with updated code moved into libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8c603",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1a805",
   "metadata": {},
   "source": [
    "Third-party modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ea74f",
   "metadata": {},
   "source": [
    "Switch to the parent directory so paths can resolve and we write to the right directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd().resolve()\n",
    "project_root = cwd.parent if cwd.name == \"notebooks\" else cwd\n",
    "scripts_dir = project_root / \"scripts\"\n",
    "if scripts_dir.is_dir():\n",
    "    if cwd != project_root:\n",
    "        print(f\"Changing working directory from {cwd} to {project_root}\")\n",
    "        os.chdir(project_root)  # Change to the project root directory.\n",
    "print(\"Working directory:\", pathlib.Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5026e",
   "metadata": {},
   "source": [
    "Add imports from within the project (depends on prior cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcats import constants\n",
    "from lcats import stories\n",
    "from lcats import utils\n",
    "\n",
    "from lcats.analysis import corpus_surveyor\n",
    "from lcats.analysis import graph_plotters\n",
    "from lcats.analysis import llm_extractor\n",
    "from lcats.analysis import scene_analysis\n",
    "from lcats.analysis import story_analysis\n",
    "from lcats.analysis import story_processors\n",
    "from lcats.analysis import text_segmenter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d773b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "RELOAD_MODULES = [\n",
    "    constants,\n",
    "    stories,\n",
    "    corpus_surveyor,\n",
    "    graph_plotters,\n",
    "    llm_extractor,\n",
    "    scene_analysis,\n",
    "    story_analysis,\n",
    "    story_processors,\n",
    "    text_segmenter,\n",
    "    utils,\n",
    "]\n",
    "def reloader():\n",
    "    for module in RELOAD_MODULES:\n",
    "        print(\"Reloading\", module)\n",
    "        reload(module)\n",
    "    print(\"Reloading complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b811a20",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713a9f",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ad95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the notebook is executing (absolute, resolved)\n",
    "CURRENT_PATH = pathlib.Path.cwd().resolve()\n",
    "\n",
    "# Project root = formerly parent of notebooks/, now just current dir\n",
    "# PROJECT_ROOT = CURRENT_PATH.parent \n",
    "PROJECT_ROOT = CURRENT_PATH\n",
    "\n",
    "# Local data/output inside the project\n",
    "DEV_CORPUS = (PROJECT_ROOT / \"data\")\n",
    "DEV_OUTPUT = (PROJECT_ROOT / \"output\")\n",
    "\n",
    "# Sibling-level resources (one level up from project root)\n",
    "GIT_CORPUS = (PROJECT_ROOT.parent / \"corpora\")\n",
    "OPENIA_API_KEYS_ENV = (PROJECT_ROOT.parent / \".secrets\" / \"openai_api_keys.env\")\n",
    "\n",
    "def check_path(path: pathlib.Path, description: str) -> None:\n",
    "    if path.exists():\n",
    "        print(f\"Found {description} at: {path}\")\n",
    "    else:\n",
    "        print(f\"Missing {description} from: {path}\")\n",
    "\n",
    "check_path(DEV_CORPUS, \"DEV_CORPUS\")\n",
    "check_path(DEV_OUTPUT, \"DEV_OUTPUT\")\n",
    "check_path(GIT_CORPUS, \"GIT_CORPUS\")\n",
    "check_path(OPENIA_API_KEYS_ENV, \"OPENIA_API_KEYS_ENV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working corpora\n",
    "# CORPORA_ROOT = project_root / \"data\"\n",
    "# Checked-in corpora\n",
    "CORPORA_ROOT = project_root / \"..\" / \"corpora\"\n",
    "CORPORA_ROOT = CORPORA_ROOT.resolve()  # Resolve to absolute path.\n",
    "\n",
    "print(\"Corpora root:\", CORPORA_ROOT)\n",
    "print(\"Corpora top-level directories:\", end=\" \")\n",
    "os.listdir(CORPORA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d927d4",
   "metadata": {},
   "source": [
    "### OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce48e35",
   "metadata": {},
   "source": [
    "Get the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79666bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(OPENIA_API_KEYS_ENV)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248687b",
   "metadata": {},
   "source": [
    "Verify that we can get a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "print(f\"Loaded OpenAI client: {client} with version: {client._version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6ee9d",
   "metadata": {},
   "source": [
    "Verify the API is working. This week. And that you have credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87640168",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a one-sentence bedtime story about a starship captain visiting a planet.\"\n",
    ")\n",
    "\n",
    "print(f\"Story generated on: {datetime.date.today()}:\")\n",
    "utils.pprint(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ea481",
   "metadata": {},
   "source": [
    "## Corpora-level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f0b6d",
   "metadata": {},
   "source": [
    "### Story Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c130df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run from within a notebook, the corpora root is two paths up from the notebook's location.\n",
    "CORPORA_ROOT = GIT_CORPUS  # Checked-in corpora\n",
    "# CORPORA_ROOT = DEV_CORPUS  # Command line working corpora\n",
    "\n",
    "# Now load the corpora\n",
    "corpora = stories.Corpora(CORPORA_ROOT)\n",
    "\n",
    "print(\"Loaded corpora:\")\n",
    "print(f\" - root: {corpora.corpora_root}\")\n",
    "print(f\" - corpora: {len(corpora.corpora)}\")\n",
    "print(f\" - stories: {len(corpora.stories)}\")\n",
    "print()\n",
    "\n",
    "print(f\"Example story: corpora.stories[0]:\")\n",
    "example_story = corpora.stories[0]\n",
    "print(f\"Story type: {type(example_story)} with a body of {len(example_story.body)} characters.\")\n",
    "print(example_story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a97b90",
   "metadata": {},
   "source": [
    "### JSON Corpora Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83456396",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_stories = corpus_surveyor.find_corpus_stories(CORPORA_ROOT)\n",
    "len(json_stories)\n",
    "print(utils.sml(json_stories))\n",
    "print(\"Type of path element:\", type(json_stories[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c73fa9",
   "metadata": {},
   "source": [
    "### Corpora Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can test with a sample of 10 stories for speed.\n",
    "# short_stories = stories[:10]  # lol\n",
    "# story_stats, author_stats = survey.compute_corpus_stats(short_stories)\n",
    "story_stats, author_stats = corpus_surveyor.compute_corpus_stats(json_stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de024d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1414ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a340dda",
   "metadata": {},
   "source": [
    "### Corpora Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = graph_plotters.plot_author_stories_vs_tokens(author_stats, annotate_top=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = graph_plotters.plot_author_stories_vs_tokens_sns(author_stats, annotate_top=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = graph_plotters.plot_tokens_per_story_by_author(story_stats, top_n=25, min_stories=2, rotate_labels=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdff5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = graph_plotters.plot_tokens_per_story_by_author_sns(story_stats, top_n=24, min_stories=2, rotate_labels=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf02d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = graph_plotters.plot_tokens_per_story_vs_stories(\n",
    "    author_stats, annotate_top=15, log_y=True, jitter=0.05, spread_step=4, x_spread=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7868122",
   "metadata": {},
   "source": [
    "## Scene-Sequel Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46178a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_extractor = scene_analysis.make_segment_extractor(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_extraction = segment_extractor.extract(example_story.body)\n",
    "example_result = example_extraction['extracted_output']\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_analysis.display_segments(example_story.body, example_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b15eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_extractor = scene_analysis.make_semantics_extractor(client)\n",
    "annotated_segments = scene_analysis.annotate_segments_with_semantics(\n",
    "    example_story.body,\n",
    "    example_result,\n",
    "    semantic_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da069f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_analysis.display_annotated_segments(annotated_segments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5b343",
   "metadata": {},
   "source": [
    "## Process Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d052b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_stories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c1c9d",
   "metadata": {},
   "source": [
    "Acquire a sample of 10 randomly selected stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16529a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathify(paths: List[str]) -> List[pathlib.Path]:\n",
    "    return list(map(pathlib.Path, paths))\n",
    "\n",
    "# print(\"[\")\n",
    "# for sample in random.sample(json_stories, 100):\n",
    "#     print(f\"    \\\"{sample}\\\",\")\n",
    "# print(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9085ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_OF_10 = pathify([\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_crystal_ray.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/grimm/old_man_and_his_grandson.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_phantom_of_bogue_holauba_1911.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/anderson/elderbush.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/grimm/king_of_the_golden_mountain.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/sherlock/noble_bachelor.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_little_man_who_wasnt_quite.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/monsoons_of_death.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/shipwreck_in_the_sky.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_voice_in_the_fog.json\",\n",
    "])\n",
    "SAMPLE_OF_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_OF_100 = pathify([\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_doors_of_death.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/travelogue.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/anderson/real_princess.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/passion_fruit.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/routine_for_a_hornet.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_little_hunchback_zia.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_soul_of_nicholas_snyders;_or,_the_miser_of_zandam.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_disembodied_man.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_queen_of_space.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/halima_and_the_scorpions_1905.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/point_of_departure.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/far_enough_to_touch.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/planet_of_creation.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_ring_bonanza.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/hemingway/alpine_idyll.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/dig_me_no_grave.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/doorstep.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/milk_run.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_ties_that_bind.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/when_oscar_went_wild.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/fifty_per_cent_prophet.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_sweeper_of_loray.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_marriage_of_william_durrant.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_cobbler_in_the_devils_kitchen_from_\\\"_mackinac_and_lake_stories\\\"_1899.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/ohenry/skylight_room.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_worlds_of_joe_shannon.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/grimm/twelve_huntsmen.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/brknks_bounty.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/welcome,_martians!.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_rogue_waveform.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/cum_grano_salis.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_eyes_have_it.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/when_the_sun_went_out.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/greener_than_spruce.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/a_chilhowee_lily_1911.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_novel_and_the_common_school.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/thirty_degrees_cattywonkus.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/people_soup.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/new_hire.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/morgue_ship.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/anderson/fir_tree.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_spectre_in_the_cart_1908.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_outer_quiet.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_yellow_wallpaper.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/has_anyone_here_seen_kelly?.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/hagertys_enzymes.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/marianson_from_\\\"_mackinac_and_lake_stories\\\"_1899.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/destinationâ€”_death.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/radio_v_rays.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/x_marks_the_asteroid.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_penultimate_trump.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_good_work.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_seven_missionaries.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/george_loves_gistla.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/luna_escapade.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/menace_of_the_mists.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/code.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/\\\"_pig_headed\\\"_sailor_men_from_\\\"_the_strange_adventure_of_james_shervinton,_and_other_stories\\\"_1902.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/in_the_bad_lands.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/stories_of_christmas_and_the_bowie_knife.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/among_the_scented_ones.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/rat_race.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_hunters_lodge_case.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/lovecraft/at_the_mountains_of_madness.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_un_reconstructed_woman.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/trouble_on_sun_side.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/competition.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/ohenry/gift_of_the_magi.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/stairway_to_the_stars.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_waif_woman.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/tongues_of_the_moon.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_violators.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_hunted_heroes.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_hour_of_battle.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/raiders_of_the_universes.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_voyage_of_vanishing_men.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/ride_the_crepe_ring.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/a_madman_on_board.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_valor_of_cappen_varra.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_crystal_crypt.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_sound_of_silence.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/wodehouse/at_geisenheimer's.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_story_of_gombi.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/love_among_the_robots.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/big_stupe.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/anderson/shoes_of_fortune.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_impossible_pirate.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_flight_of_the_eagle.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/pastoral_affair.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_terrible_answer.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/all_that_earthly_remains.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/that_pup.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/in_his_image.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/derelict.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/lovecraft/the_colour_out_of_space.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/traders_risk.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/picnic.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_good_seed.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/subversive.json\",\n",
    "    \"/Users/centaur/Workspace/LCATS/LCATS/corpora/massQuantities/the_vegans_were_curious.json\",\n",
    "])\n",
    "len(SAMPLE_OF_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output = corpus_surveyor.process_files(\n",
    "    SAMPLE_OF_10,\n",
    "    processor_function=story_processors.story_summarizer,\n",
    "    corpora_root=CORPORA_ROOT,\n",
    "    output_root=DEV_OUTPUT,\n",
    "    job_label=\"sample_summaries\",\n",
    ")\n",
    "summary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_segment_processor = story_processors.make_annotated_segment_extractor(\n",
    "    client, segment_model=\"gpt-4o\", semantic_model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = corpus_surveyor.process_files(\n",
    "    SAMPLE_OF_10,\n",
    "    corpora_root=CORPORA_ROOT,\n",
    "    output_root=DEV_OUTPUT,\n",
    "    processor_function=annotated_segment_processor,\n",
    "    job_label=\"scene_semantics\",\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9856f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hundred_summary = corpus_surveyor.process_files(\n",
    "    SAMPLE_OF_100,\n",
    "    corpora_root=CORPORA_ROOT,\n",
    "    output_root=DEV_OUTPUT,\n",
    "    processor_function=annotated_segment_processor,\n",
    "    job_label=\"scene_semantics_100\",\n",
    "    verbose=True,\n",
    ")\n",
    "hundred_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10_dir = DEV_OUTPUT / \"scene_semantics\"\n",
    "sample_10_json = corpus_surveyor.find_corpus_stories(sample_10_dir)\n",
    "len(sample_10_json)\n",
    "print(utils.sml(sample_10_json))\n",
    "\n",
    "sample_json = sample_10_json[0]\n",
    "sample_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cf3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sample_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    sample_data = json.load(f)\n",
    "utils.sm(str(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd87c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_dir = DEV_OUTPUT / \"scene_semantics_100\"\n",
    "sample_100_json = corpus_surveyor.find_corpus_stories(sample_100_dir)\n",
    "len(sample_100_json)\n",
    "print(utils.sml(sample_100_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a16f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_story_metrics(data_root: Union[str, pathlib.Path],\n",
    "                          json_path: Union[str, pathlib.Path]) -> Dict[str, Any]:\n",
    "    \"\"\"Extract story metrics from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data_root (Union[str, pathlib.Path]): Root directory of the corpus.\n",
    "        json_path (Union[str, pathlib.Path]): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary containing the extracted story metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure we have valid Path objects.\n",
    "    data_root = pathlib.Path(data_root)\n",
    "    json_path = pathlib.Path(json_path)\n",
    "    try:\n",
    "        with json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"warn: skipping unreadable JSON {json_path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # Get title/authors/body and compute uniqueness key\n",
    "    story_id = str(json_path.resolve().relative_to(data_root.resolve()).with_suffix(\"\"))\n",
    "    title, authors, _ = story_analysis.extract_title_authors_body(data)\n",
    "\n",
    "    # Metrics\n",
    "    title_chars = len(title)\n",
    "    title_words = story_analysis.word_count(title)\n",
    "    title_tokens = story_analysis.token_count(title)\n",
    "\n",
    "    body_chars = data.get('body_length_chars')\n",
    "    body_words = data.get('body_length_words')\n",
    "    body_tokens = data.get('body_length_tokens')\n",
    "    body_paragraphs = data.get('body_length_paragraphs')\n",
    "\n",
    "    segments = data.get('segments')\n",
    "    segment_count = len(segments) if segments else 0\n",
    "    scene_type_analysis = scene_analysis.summarize_type_agreement(data)\n",
    "    original_dramatic_scene = scene_type_analysis['by_extractor']['dramatic_scene']\n",
    "    original_dramatic_sequel = scene_type_analysis['by_extractor']['dramatic_sequel']\n",
    "    original_narrative_scene = scene_type_analysis['by_extractor']['narrative_scene']\n",
    "    original_other_scene = scene_type_analysis['by_extractor']['other']\n",
    "    original_unknown_scene = scene_type_analysis['by_extractor']['unknown']\n",
    "    auditor_dramatic_scene = scene_type_analysis['by_auditor']['dramatic_scene']\n",
    "    auditor_dramatic_sequel = scene_type_analysis['by_auditor']['dramatic_sequel']\n",
    "    auditor_narrative_scene = scene_type_analysis['by_auditor']['narrative_scene']\n",
    "    auditor_other_scene = scene_type_analysis['by_auditor']['other']\n",
    "    auditor_unknown_scene = scene_type_analysis['by_auditor']['unknown']\n",
    "    scene_agreements = scene_type_analysis['agreements']\n",
    "    scene_disagreements = scene_type_analysis['disagreements']\n",
    "    scene_agreement_rate = scene_type_analysis['agreement_rate']\n",
    "    scene_total = scene_type_analysis['segments_total']\n",
    "\n",
    "    return{\n",
    "            \"path\": str(json_path),\n",
    "            \"story_id\": story_id,\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"n_authors\": len(authors),\n",
    "\n",
    "            \"title_words\": title_words,\n",
    "            \"title_chars\": title_chars,\n",
    "            \"title_tokens\": title_tokens,\n",
    "\n",
    "            \"body_words\": body_words,\n",
    "            \"body_chars\": body_chars,\n",
    "            \"body_tokens\": body_tokens,\n",
    "            \"body_paragraphs\": body_paragraphs,\n",
    "\n",
    "            \"segment_count\": segment_count,\n",
    "            \"original_dramatic_scene\": original_dramatic_scene,\n",
    "            \"original_dramatic_sequel\": original_dramatic_sequel,\n",
    "            \"original_narrative_scene\": original_narrative_scene,\n",
    "            \"original_other_scene\": original_other_scene,\n",
    "            \"original_unknown_scene\": original_unknown_scene,\n",
    "            \"auditor_dramatic_scene\": auditor_dramatic_scene,\n",
    "            \"auditor_dramatic_sequel\": auditor_dramatic_sequel,\n",
    "            \"auditor_narrative_scene\": auditor_narrative_scene,\n",
    "            \"auditor_other_scene\": auditor_other_scene,\n",
    "            \"auditor_unknown_scene\": auditor_unknown_scene,\n",
    "            \"scene_agreements\": scene_agreements,\n",
    "            \"scene_disagreements\": scene_disagreements,\n",
    "            \"scene_agreement_rate\": scene_agreement_rate,\n",
    "            \"scene_total\": scene_total,\n",
    "        }\n",
    "\n",
    "\n",
    "def compute_semantic_stats(\n",
    "        data_root: pathlib.Path,\n",
    "        json_paths: Iterable[Union[str, pathlib.Path]]\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Process stories in a corpus to extract story and scene metrics.\n",
    "\n",
    "    Given an iterable of JSON file paths, produce:\n",
    "      - story_stats: one row per JSON file with story-level metrics\n",
    "    Columns in story_stats:\n",
    "        path, story_id, title, authors, n_authors,\n",
    "        title_words, title_chars, title_tokens,\n",
    "        body_words, body_chars, body_tokens\n",
    "    \"\"\"\n",
    "    story_rows: List[Dict[str, Any]] = []\n",
    "    for json_path in tqdm(json_paths):\n",
    "        # Extract story metrics; skip if unreadable\n",
    "        story_metrics = extract_story_metrics(data_root, json_path)\n",
    "        if story_metrics:\n",
    "            story_rows.append(story_metrics)\n",
    "    print(f\"Processed {len(story_rows)} valid stories.\")\n",
    "\n",
    "    # Build story_stats DataFrame\n",
    "    story_stats = pd.DataFrame(story_rows)\n",
    "    return None if story_stats.empty else story_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff32e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10_segments_df = compute_semantic_stats(data_root=sample_10_dir, json_paths=sample_10_json)\n",
    "sample_10_segments_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2caa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_segments_df = compute_semantic_stats(data_root=sample_100_dir, json_paths=sample_100_json)\n",
    "sample_100_segments_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e64efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_segments_df = pd.concat([sample_10_segments_df, sample_100_segments_df], ignore_index=True)\n",
    "joint_segments_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e99990",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_segments_df.segment_count.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_segments_df.original_dramatic_scene.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_segments_df.original_dramatic_sequel.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8516c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_segments_df.scene_disagreements.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c910ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "(joint_segments_df.segment_count == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(joint_segments_df.original_dramatic_scene == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351be73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(joint_segments_df.original_dramatic_sequel == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(joint_segments_df.scene_disagreements == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_segments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a52f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segments_vs_tokens_matplotlib(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    prefix: str = \"auditor_\",\n",
    "    log_x: bool = False,\n",
    "    figsize: tuple[int, int] = (9, 6),\n",
    ") -> None:\n",
    "    \"\"\"Scatter plot of segment metrics vs body_tokens using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with the required columns.\n",
    "        prefix: \"auditor_\" or \"original_\" to select which scene counts to use.\n",
    "        log_x: If True, set x-axis to log scale (useful for wide token ranges).\n",
    "        figsize: Figure size (width, height) in inches.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If required columns are missing.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"Segments\": \"segment_count\",\n",
    "        \"Narrative scenes\": f\"{prefix}narrative_scene\",\n",
    "        \"Dramatic scenes\": f\"{prefix}dramatic_scene\",\n",
    "        \"Dramatic sequels\": f\"{prefix}dramatic_sequel\",\n",
    "        \"Scene disagreements\": \"scene_disagreements\",\n",
    "    }\n",
    "\n",
    "    required = [\"body_tokens\", *metrics.values()]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for label, col in metrics.items():\n",
    "        plt.scatter(\n",
    "            df[\"body_tokens\"], df[col],\n",
    "            s=24, alpha=0.75, linewidths=0.5, label=label\n",
    "        )\n",
    "\n",
    "    if log_x:\n",
    "        plt.xscale(\"log\")\n",
    "\n",
    "    plt.xlabel(\"Body tokens\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Segments vs. Body Tokens\")\n",
    "    plt.legend(title=\"Metric\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_segments_vs_tokens_matplotlib(joint_segments_df, prefix=\"original_\", log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8adac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segments_vs_tokens_seaborn(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    prefix: str = \"auditor_\",\n",
    "    log_x: bool = False,\n",
    "    figsize: tuple[int, int] = (9, 6),\n",
    ") -> None:\n",
    "    \"\"\"Scatter plot of segment metrics vs body_tokens using Seaborn.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with the required columns.\n",
    "        prefix: \"auditor_\" or \"original_\" to select which scene counts to use.\n",
    "        log_x: If True, set x-axis to log scale (useful for wide token ranges).\n",
    "        figsize: Figure size (width, height) in inches.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If required columns are missing.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"Segments\": \"segment_count\",\n",
    "        \"Narrative scenes\": f\"{prefix}narrative_scene\",\n",
    "        \"Dramatic scenes\": f\"{prefix}dramatic_scene\",\n",
    "        \"Dramatic sequels\": f\"{prefix}dramatic_sequel\",\n",
    "        \"Scene disagreements\": \"scene_disagreements\",\n",
    "    }\n",
    "\n",
    "    required = [\"body_tokens\", *metrics.values()]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # Tidy/long form for hue separation.\n",
    "    long_df = (\n",
    "        df[[\"body_tokens\", *metrics.values()]]\n",
    "        .rename(columns={v: k for k, v in metrics.items()})\n",
    "        .melt(id_vars=\"body_tokens\", var_name=\"metric\", value_name=\"count\")\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.scatterplot(\n",
    "        data=long_df, x=\"body_tokens\", y=\"count\", hue=\"metric\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    if log_x:\n",
    "        ax.set(xscale=\"log\")\n",
    "\n",
    "    ax.set_title(\"Segments vs. Body Tokens\")\n",
    "    ax.set_xlabel(\"Body tokens\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend(title=\"Metric\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_segments_vs_tokens_seaborn(joint_segments_df, prefix=\"original_\", log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene_composition_by_length_bins(\n",
    "    df,\n",
    "    *,\n",
    "    prefix=\"auditor_\",         # or \"original_\"\n",
    "    n_bins=8,\n",
    "    binning=\"quantile\",        # \"quantile\" (balanced counts) or \"fixed\"\n",
    "    figsize=(10, 5),\n",
    "    title=\"Scene composition by story length (100% per bin)\"\n",
    "):\n",
    "    # Prepare proportions per story\n",
    "    counts = {\n",
    "        \"narrative_scene\": f\"{prefix}narrative_scene\",\n",
    "        \"dramatic_scene\": f\"{prefix}dramatic_scene\",\n",
    "        \"dramatic_sequel\": f\"{prefix}dramatic_sequel\",\n",
    "        \"other\": f\"{prefix}other_scene\",\n",
    "        \"unknown\": f\"{prefix}unknown_scene\",\n",
    "    }\n",
    "    required = [\"body_tokens\", \"segment_count\", *counts.values()]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    safe = df[df[\"segment_count\"] > 0].copy()\n",
    "    for k, col in counts.items():\n",
    "        safe[f\"p_{k}\"] = safe[col] / safe[\"segment_count\"]\n",
    "\n",
    "    # Make token bins\n",
    "    if binning == \"quantile\":\n",
    "        safe[\"len_bin\"] = pd.qcut(safe[\"body_tokens\"], q=n_bins, duplicates=\"drop\")\n",
    "    else:\n",
    "        safe[\"len_bin\"] = pd.cut(safe[\"body_tokens\"], bins=n_bins)\n",
    "\n",
    "    grp = (safe\n",
    "           .groupby(\"len_bin\", observed=True)[[f\"p_{k}\" for k in counts]]\n",
    "           .mean()\n",
    "           .reset_index())\n",
    "\n",
    "    # 100% stacked bar\n",
    "    ax = grp.set_index(\"len_bin\").plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        figsize=figsize,\n",
    "        width=0.9,\n",
    "        ylabel=\"Proportion of segments\",\n",
    "        title=title\n",
    "    )\n",
    "    ax.set_xlabel(\"Body token bins\")\n",
    "    ax.legend(title=\"Type\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    ax.margins(x=0.01)\n",
    "    plt.tight_layout()\n",
    "plot_scene_composition_by_length_bins(joint_segments_df, prefix=\"auditor_\", n_bins=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene_proportion_trends(\n",
    "    df,\n",
    "    *,\n",
    "    prefix=\"auditor_\",\n",
    "    lowess=True,               # requires statsmodels via seaborn; if unavailable, set False\n",
    "    figsize=(10, 6),\n",
    "    title=\"Scene-type proportions vs. story length\"\n",
    "):\n",
    "    counts = {\n",
    "        \"Narrative\": f\"{prefix}narrative_scene\",\n",
    "        \"Dramatic scene\": f\"{prefix}dramatic_scene\",\n",
    "        \"Dramatic sequel\": f\"{prefix}dramatic_sequel\",\n",
    "        \"Other\": f\"{prefix}other_scene\",\n",
    "        \"Unknown\": f\"{prefix}unknown_scene\",\n",
    "    }\n",
    "    required = [\"body_tokens\", \"segment_count\", *counts.values()]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    safe = df[df[\"segment_count\"] > 0].copy()\n",
    "    for label, col in counts.items():\n",
    "        safe[f\"p_{label}\"] = safe[col] / safe[\"segment_count\"]\n",
    "\n",
    "    long_df = (\n",
    "        safe[[\"body_tokens\", *[f\"p_{k}\" for k in counts]]]\n",
    "        .rename(columns={f\"p_{k}\": k for k in counts})\n",
    "        .melt(id_vars=\"body_tokens\", var_name=\"metric\", value_name=\"prop\")\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.regplot(\n",
    "        data=long_df, x=\"body_tokens\", y=\"prop\",\n",
    "        scatter=False, lowess=lowess, ci=None, line_kws={\"alpha\": 0.9}\n",
    "    )\n",
    "    # Draw multiple lines by facetting hue (overlay)\n",
    "    for name, sub in long_df.groupby(\"metric\"):\n",
    "        sns.regplot(\n",
    "            data=sub, x=\"body_tokens\", y=\"prop\",\n",
    "            scatter=False, lowess=lowess, ci=None, label=name\n",
    "        )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Body tokens\")\n",
    "    ax.set_ylabel(\"Proportion of segments\")\n",
    "    ax.legend(title=\"Type\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_scene_proportion_trends(joint_segments_df, prefix=\"auditor_\", lowess=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c281de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hexbin_segments_vs_tokens(\n",
    "    df,\n",
    "    *,\n",
    "    gridsize=30,\n",
    "    figsize=(8, 6),\n",
    "    title=\"Density of segment_count vs. body_tokens\"\n",
    "):\n",
    "    required = [\"body_tokens\", \"segment_count\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    hb = plt.hexbin(\n",
    "        df[\"body_tokens\"], df[\"segment_count\"],\n",
    "        gridsize=gridsize, mincnt=1, cmap=\"viridis\", linewidths=0\n",
    "    )\n",
    "    plt.colorbar(hb, label=\"Stories per bin\")\n",
    "    plt.xlabel(\"Body tokens\")\n",
    "    plt.ylabel(\"Segment count\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_hexbin_segments_vs_tokens(joint_segments_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disagreement_rate_by_bins(\n",
    "    df,\n",
    "    *,\n",
    "    n_bins=8,\n",
    "    binning=\"quantile\",\n",
    "    figsize=(9, 5),\n",
    "    title=\"Scene disagreement rate by story length bin\"\n",
    "):\n",
    "    required = [\"body_tokens\", \"scene_disagreements\", \"scene_total\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    safe = df[df[\"scene_total\"] > 0].copy()\n",
    "    safe[\"disagree_rate\"] = safe[\"scene_disagreements\"] / safe[\"scene_total\"]\n",
    "\n",
    "    if binning == \"quantile\":\n",
    "        safe[\"len_bin\"] = pd.qcut(safe[\"body_tokens\"], q=n_bins, duplicates=\"drop\")\n",
    "    else:\n",
    "        safe[\"len_bin\"] = pd.cut(safe[\"body_tokens\"], bins=n_bins)\n",
    "\n",
    "    stats = safe.groupby(\"len_bin\", observed=True)[\"disagree_rate\"].agg([\"mean\", \"median\"]).reset_index()\n",
    "\n",
    "    ax = stats.plot(\n",
    "        x=\"len_bin\", y=[\"mean\", \"median\"], marker=\"o\", figsize=figsize,\n",
    "        title=title\n",
    "    )\n",
    "    ax.set_xlabel(\"Body token bins\")\n",
    "    ax.set_ylabel(\"Disagreement rate\")\n",
    "    ax.legend(title=\"\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_disagreement_rate_by_bins(joint_segments_df, n_bins=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831668d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene_count_trends(\n",
    "    df,\n",
    "    *,\n",
    "    prefix=\"auditor_\",                     # or \"original_\"\n",
    "    features=None,                        # dict: display label -> column name\n",
    "    smoother=\"binmean\",                   # \"binmean\" or \"lowess\"\n",
    "    n_bins=12,\n",
    "    binning=\"quantile\",                   # \"quantile\" or \"fixed\"\n",
    "    scatter=True,                         # overlay raw scatter points\n",
    "    log_x=False,\n",
    "    max_body_tokens=None,                 # axis limit only (no filtering)\n",
    "    max_scene_count=None,                 # axis limit only (no clipping)\n",
    "    min_body_tokens=None,                 # axis limit only (no filtering)\n",
    "    min_scene_count=None,                 # axis limit only (no clipping)\n",
    "    markers=None,                         # dict label->marker or list of markers\n",
    "    figsize=(10, 6),\n",
    "    title=\"Scene counts vs. story length\",\n",
    "):\n",
    "    \"\"\"Plot total scene counts vs body_tokens with optional smoothing.\n",
    "\n",
    "    This version does NOT filter or clip the data. `max_body_tokens` and\n",
    "    `max_scene_count` are applied only as axis limits so outliers remain in\n",
    "    the fit but are not displayed if outside the view.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing 'body_tokens' and scene count columns.\n",
    "        prefix: \"auditor_\" or \"original_\" to pick which scene counts to use.\n",
    "        features: Optional mapping label -> column name. If None:\n",
    "            {\n",
    "              \"Segments\": \"segment_count\",\n",
    "              \"Narrative scenes\": f\"{prefix}narrative_scene\",\n",
    "              \"Dramatic scenes\": f\"{prefix}dramatic_scene\",\n",
    "              \"Dramatic sequels\": f\"{prefix}dramatic_sequel\",\n",
    "              \"Disagreements\": \"scene_disagreements\",\n",
    "            }\n",
    "        smoother: \"binmean\" (mean per length bin) or \"lowess\" (seaborn/regplot).\n",
    "        n_bins: Number of bins for \"binmean\" smoothing (and for fixed/quantile).\n",
    "        binning: \"quantile\" for balanced bins, \"fixed\" for equal-width bins.\n",
    "        scatter: If True, overlay raw points for each metric.\n",
    "        log_x: If True, use a log scale for the x-axis.\n",
    "        max_body_tokens: If set, set x-axis maximum to this value.\n",
    "        max_scene_count: If set, set y-axis maximum to this value.\n",
    "        figsize: Matplotlib (width, height) in inches.\n",
    "        title: Figure title.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If required columns are missing.\n",
    "        ValueError: If `smoother` or `binning` is invalid.\n",
    "    \"\"\"\n",
    "    if features is None:\n",
    "        features = {\n",
    "            \"Segments\": \"segment_count\",\n",
    "            \"Narrative scenes\": f\"{prefix}narrative_scene\",\n",
    "            \"Dramatic scenes\": f\"{prefix}dramatic_scene\",\n",
    "            \"Dramatic sequels\": f\"{prefix}dramatic_sequel\",\n",
    "            \"Disagreements\": \"scene_disagreements\",\n",
    "        }\n",
    "\n",
    "    required = [\"body_tokens\", *features.values()]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    if smoother not in {\"binmean\", \"lowess\"}:\n",
    "        raise ValueError(\"smoother must be 'binmean' or 'lowess'\")\n",
    "    if binning not in {\"quantile\", \"fixed\"}:\n",
    "        raise ValueError(\"binning must be 'quantile' or 'fixed'\")\n",
    "    \n",
    "    # Marker assignment\n",
    "    labels = list(features.keys())\n",
    "    default_cycle = [\"o\", \"s\", \"D\", \"^\", \"v\", \"P\", \"X\", \"*\", \"h\", \"<\", \">\"]\n",
    "    if markers is None:\n",
    "        marker_map = {lab: default_cycle[i % len(default_cycle)] for i, lab in enumerate(labels)}\n",
    "    elif isinstance(markers, dict):\n",
    "        marker_map = {lab: markers.get(lab, default_cycle[i % len(default_cycle)])\n",
    "                      for i, lab in enumerate(labels)}\n",
    "        print   (marker_map)\n",
    "    else:\n",
    "        # Treat as sequence in feature order\n",
    "        marker_map = {lab: markers[i % len(markers)] for i, lab in enumerate(labels)}\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Optional raw scatter overlay (all data shown; axis limits may hide some).\n",
    "    if scatter:\n",
    "        for _, col in features.items():\n",
    "            sns.scatterplot(\n",
    "                data=df, x=\"body_tokens\", y=col,\n",
    "                alpha=0.25, s=18, linewidth=0, label=None\n",
    "            )\n",
    "\n",
    "    if smoother == \"lowess\":\n",
    "        # LOWESS line per metric over ALL data (display cropped by axis limits).\n",
    "        for label, col in features.items():\n",
    "            sns.regplot(\n",
    "                data=df, x=\"body_tokens\", y=col,\n",
    "                lowess=True, scatter=False, ci=None, label=label\n",
    "            )\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        # BINMEAN smoother over ALL data (display cropped by axis limits).\n",
    "        work = df[[\"body_tokens\", *features.values()]].copy()\n",
    "\n",
    "        # Create bins over body_tokens.\n",
    "        if binning == \"quantile\":\n",
    "            work[\"len_bin\"] = pd.qcut(work[\"body_tokens\"], q=n_bins, duplicates=\"drop\")\n",
    "        else:\n",
    "            work[\"len_bin\"] = pd.cut(work[\"body_tokens\"], bins=n_bins)\n",
    "\n",
    "        metric_cols = list(features.values())\n",
    "        for c in metric_cols:\n",
    "            work[c] = pd.to_numeric(work[c], errors=\"coerce\")\n",
    "\n",
    "        agg = (\n",
    "            work.groupby(\"len_bin\", observed=True)[metric_cols]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        def _mid(iv):\n",
    "            try:\n",
    "                return (iv.left + iv.right) / 2\n",
    "            except Exception:\n",
    "                return float(\"nan\")\n",
    "\n",
    "        agg[\"x_mid\"] = agg[\"len_bin\"].apply(_mid)\n",
    "\n",
    "        long_df = agg.melt(\n",
    "            id_vars=[\"len_bin\", \"x_mid\"],\n",
    "            value_vars=metric_cols,\n",
    "            var_name=\"metric\",\n",
    "            value_name=\"count\",\n",
    "        )\n",
    "        inv = {v: k for k, v in features.items()}\n",
    "        long_df[\"metric\"] = long_df[\"metric\"].map(inv)\n",
    "\n",
    "        ax = sns.lineplot(\n",
    "            # data=long_df, x=\"x_mid\", y=\"count\", hue=\"metric\", marker=\"o\"\n",
    "            data=long_df, x=\"x_mid\", y=\"count\", hue=\"metric\", style=\"metric\",\n",
    "            markers=marker_map, dashes=False,  # distinct shapes, solid lines\n",
    "            )\n",
    "\n",
    "    if log_x:\n",
    "        plt.xscale(\"log\")\n",
    "\n",
    "    # Axis limits only (no data filtering/clipping)\n",
    "    if max_body_tokens is not None:\n",
    "        ax.set_xlim(left=-0.5)\n",
    "        ax.set_xlim(right=max_body_tokens)\n",
    "    if max_scene_count is not None:\n",
    "        ax.set_ylim(bottom=-0.5)\n",
    "        ax.set_ylim(top=max_scene_count)\n",
    "    if min_body_tokens is not None:\n",
    "        ax.set_xlim(left=min_body_tokens)\n",
    "    if min_scene_count is not None:\n",
    "        ax.set_ylim(bottom=min_scene_count)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Body tokens\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    # ax.legend(title=\"Metric\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    # ax.legend(title=\"Metric\", bbox_to_anchor=(0.7, 1), loc=\"upper left\")\n",
    "    ax.legend(bbox_to_anchor=(0.75, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eede244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default features (Segments, Narrative, Dramatic, Sequel, Disagreements)\n",
    "plot_scene_count_trends(joint_segments_df, prefix=\"auditor_\", smoother=\"binmean\", n_bins=8,\n",
    "                        max_body_tokens=12100, max_scene_count=12, scatter=True,\n",
    "                        min_body_tokens=1900,\n",
    "                        features = {\n",
    "            \"Extracted Segments\": \"segment_count\",\n",
    "            \"Dramatic Scenes\": f\"auditor_dramatic_scene\",\n",
    "            \"Dramatic Sequels\": f\"auditor_dramatic_sequel\",\n",
    "            \"Disagreements\": \"scene_disagreements\",\n",
    "        },\n",
    "            markers={\n",
    "        \"Extracted Segments\": \"o\",\n",
    "        \"Dramatic Scenes\": \"D\",\n",
    "        \"Dramatic Sequels\": \"^\",\n",
    "        \"Disagreements\": \"X\",\n",
    "    },\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOWESS smoothing (requires statsmodels via seaborn)\n",
    "# plot_scene_count_trends(joint_segments_df, prefix=\"auditor_\", smoother=\"lowess\", scatter=False)\n",
    "\n",
    "# Custom features (pick any subset/rename)\n",
    "custom = {\n",
    "    \"Segments\": \"segment_count\",\n",
    "    \"Dramatic scenes\": \"auditor_dramatic_scene\",\n",
    "    \"Sequels\": \"auditor_dramatic_sequel\",\n",
    "}\n",
    "plot_scene_count_trends(joint_segments_df, features=custom, smoother=\"binmean\", n_bins=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a460c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c66ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCATS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
