{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427d9f4f",
   "metadata": {},
   "source": [
    "# Analyze Corpus, Reloaded\n",
    "\n",
    "This notebook analyzes our corpus with updated code moved into libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8c603",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1a805",
   "metadata": {},
   "source": [
    "Third-party modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ea74f",
   "metadata": {},
   "source": [
    "Switch to the parent directory so paths can resolve and we write to the right directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd().resolve()\n",
    "project_root = cwd.parent if cwd.name == \"notebooks\" else cwd\n",
    "scripts_dir = project_root / \"scripts\"\n",
    "if scripts_dir.is_dir():\n",
    "    if cwd != project_root:\n",
    "        print(f\"Changing working directory from {cwd} to {project_root}\")\n",
    "        os.chdir(project_root)  # Change to the project root directory.\n",
    "print(\"Working directory:\", pathlib.Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5026e",
   "metadata": {},
   "source": [
    "Add imports from within the project (depends on prior cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcats import constants\n",
    "from lcats import stories\n",
    "from lcats import utils\n",
    "\n",
    "from lcats.analysis import survey\n",
    "from lcats.analysis import llm_extractor\n",
    "from lcats.analysis import scenes\n",
    "from lcats.analysis import text_indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d773b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "RELOAD_MODULES = [\n",
    "    constants,\n",
    "    stories,\n",
    "    llm_extractor,\n",
    "    scenes,\n",
    "    survey,\n",
    "    text_indexing,\n",
    "    utils,\n",
    "]\n",
    "def reloader():\n",
    "    for module in RELOAD_MODULES:\n",
    "        print(\"Reloading\", module)\n",
    "        reload(module)\n",
    "    print(\"Reloading complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b811a20",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713a9f",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working corpora\n",
    "# CORPORA_ROOT = project_root / \"data\"\n",
    "# Checked-in corpora\n",
    "CORPORA_ROOT = project_root / \"..\" / \"corpora\"\n",
    "CORPORA_ROOT = CORPORA_ROOT.resolve()  # Resolve to absolute path.\n",
    "\n",
    "print(\"Corpora root:\", CORPORA_ROOT)\n",
    "print(\"Corpora top-level directories:\", end=\" \")\n",
    "os.listdir(CORPORA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5708ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_stories = survey.find_corpus_stories(CORPORA_ROOT)\n",
    "len(json_stories)\n",
    "print(utils.sml(json_stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c998e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_stories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing just with a sample of 10 stories for speed.\n",
    "# short_stories = stories[:10]  # lol\n",
    "# story_stats, author_stats = survey.compute_corpus_stats(short_stories)\n",
    "story_stats, author_stats = survey.compute_corpus_stats(json_stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de024d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1414ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = survey.plot_author_stories_vs_tokens(author_stats, annotate_top=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = survey.plot_author_stories_vs_tokens_sns(author_stats, annotate_top=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = survey.plot_tokens_per_story_by_author(story_stats, top_n=24, min_stories=2, rotate_labels=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdff5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = survey.plot_tokens_per_story_by_author_sns(story_stats, top_n=24, min_stories=2, rotate_labels=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf02d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = survey.plot_tokens_per_story_vs_stories(\n",
    "    author_stats, annotate_top=15, log_y=True, jitter=0.05, spread_step=4, x_spread=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7868122",
   "metadata": {},
   "source": [
    "## Scene-Sequel Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d04671",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Where the notebook is executing (absolute, resolved)\n",
    "CURRENT_PATH = pathlib.Path.cwd().resolve()\n",
    "\n",
    "# Project root = formerly parent of notebooks/, now just current dir\n",
    "# PROJECT_ROOT = CURRENT_PATH.parent \n",
    "PROJECT_ROOT = CURRENT_PATH\n",
    "\n",
    "# Local data/output inside the project\n",
    "DEV_CORPUS = (PROJECT_ROOT / \"data\")\n",
    "DEV_OUTPUT = (PROJECT_ROOT / \"output\")\n",
    "\n",
    "# Sibling-level resources (one level up from project root)\n",
    "GIT_CORPUS = (PROJECT_ROOT.parent / \"corpora\")\n",
    "OPENIA_API_KEYS_ENV = (PROJECT_ROOT.parent / \".secrets\" / \"openai_api_keys.env\")\n",
    "\n",
    "def check_path(path: pathlib.Path, description: str) -> None:\n",
    "    if path.exists():\n",
    "        print(f\"Found {description} at: {path}\")\n",
    "    else:\n",
    "        print(f\"Missing {description} from: {path}\")\n",
    "\n",
    "check_path(DEV_CORPUS, \"DEV_CORPUS\")\n",
    "check_path(DEV_OUTPUT, \"DEV_OUTPUT\")\n",
    "check_path(GIT_CORPUS, \"GIT_CORPUS\")\n",
    "check_path(OPENIA_API_KEYS_ENV, \"OPENIA_API_KEYS_ENV\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3ca68",
   "metadata": {},
   "source": [
    "## OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed3542",
   "metadata": {},
   "source": [
    "Get the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9dcd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(OPENIA_API_KEYS_ENV)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ae7cd",
   "metadata": {},
   "source": [
    "Verify that we can get a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4310f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "print(f\"Loaded OpenAI client: {client} with version: {client._version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce7edf",
   "metadata": {},
   "source": [
    "Verify the API is working. This week. And that you have credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46882768",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a one-sentence bedtime story about a starship captain visiting a planet.\"\n",
    ")\n",
    "\n",
    "print(f\"Story generated on: {date.today()}:\")\n",
    "utils.pprint(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a232c6",
   "metadata": {},
   "source": [
    "## Story Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4104af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run from within a notebook, the corpora root is two paths up from the notebook's location.\n",
    "CORPORA_ROOT = GIT_CORPUS  # Checked-in corpora\n",
    "# CORPORA_ROOT = DEV_CORPUS  # Command line working corpora\n",
    "\n",
    "# Now load the corpora\n",
    "corpora = stories.Corpora(CORPORA_ROOT)\n",
    "\n",
    "print(\"Loaded corpora:\")\n",
    "print(f\" - root: {corpora.corpora_root}\")\n",
    "print(f\" - corpora: {len(corpora.corpora)}\")\n",
    "print(f\" - stories: {len(corpora.stories)}\")\n",
    "print()\n",
    "\n",
    "print(f\"Example story: corpora.stories[0]:\")\n",
    "example_story = corpora.stories[0]\n",
    "print(f\"Story type: {type(example_story)} with a body of {len(example_story.body)} characters.\")\n",
    "print(example_story)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f64c3",
   "metadata": {},
   "source": [
    "## Scene and Sequel Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46178a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_extractor = scenes.make_scene_sequel_extractor(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_extraction = scene_extractor.extract(example_story.body)\n",
    "example_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_result = example_extraction['extracted_output']\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaeeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scenes(scenes):\n",
    "    for i, scene in enumerate(scenes):\n",
    "        event_type = scene.get('event_type', 'unknown')\n",
    "        reason = scene.get('reason', 'unknown')\n",
    "        event_text = scene.get('event_text', '')\n",
    "        print(f\"Scene {i}: Type {event_type}\")\n",
    "        print(f\" - Reason: {reason}\")\n",
    "        print(f\" - Text ({len(event_text)} characters): {utils.sm(event_text, limit=100)}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "display_scenes(example_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8bf3a",
   "metadata": {},
   "source": [
    "### Revised Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955cc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCENE_SEQUEL_SYSTEM_PROMPT = \"\"\"\n",
    "You are a narrative segmentation assistant. Your job is to segment a story\n",
    "into COARSE-GRAINED, contiguous narrative segments (“scenes” at the level\n",
    "of time/place), then label each segment.\n",
    "\n",
    "### Segment Types\n",
    "- dramatic_scene: a narrative scene where a focal character with a Goal takes\n",
    "  Action, encounters Conflict, and reaches a Disaster or Success (GACD).\n",
    "- dramatic_sequel: a narrative scene (typically after a dramatic_scene) where\n",
    "  a focal character experiences Emotion, reasons about Options, Anticipates\n",
    "  outcomes, and Chooses a new goal (ERAC).\n",
    "- narrative_scene: a narrative scene unified by time/place (and often\n",
    "  character/action) but lacking clear GACD/ERAC structure.\n",
    "- other: text that is not a narrative scene (e.g., front/back matter,\n",
    "  epigraphs, meta-commentary, tables of contents, etc.).\n",
    "\n",
    "### Granularity Rules (VERY IMPORTANT)\n",
    "1) Coarse segmentation only. Prefer FEWER, LARGER segments over many small ones.\n",
    "2) Split primarily on MEANINGFUL changes in TIME and/or PLACE (or explicit\n",
    "   scene-break markers like “***”, chapter headers, clear time jumps).\n",
    "3) Do NOT split simply because a paragraph or a couple of sentences shift topic.\n",
    "   If time/place is stable, keep them in the same segment.\n",
    "4) Merge tiny candidate segments (< ~3 sentences or ~100 characters) into\n",
    "   adjacent segments unless there is an explicit time/place change.\n",
    "5) Dialogue ping-pong alone is not a boundary; treat as one scene unless\n",
    "   time/place changes.\n",
    "6) A dramatic_sequel typically follows a dramatic_scene in the SAME time/place,\n",
    "   unless the text clearly relocates the character in time/place.\n",
    "7) If unsure between dramatic_scene vs narrative_scene, choose narrative_scene.\n",
    "   If unsure between dramatic_sequel vs narrative_scene, choose narrative_scene.\n",
    "\n",
    "### Output Requirements\n",
    "- Output MUST be valid JSON only (no preface or commentary).\n",
    "- Return a single object: { \"segments\": [ ... ] }.\n",
    "- For each segment, include:\n",
    "  - segment_id: integer index starting at 1.\n",
    "  - segment_type: one of \"dramatic_scene\", \"dramatic_sequel\",\n",
    "    \"narrative_scene\", \"other\".\n",
    "  - start_char, end_char: 0-based character offsets into the provided story_text\n",
    "    covering the ENTIRE contiguous segment (Python slicing semantics).\n",
    "  - summary: a short summary (not the full text), ≤ 200 characters.\n",
    "  - cohesion: brief notes identifying the unifying TIME/PLACE/CHARACTERS.\n",
    "  - gacd: for dramatic_scene only (else null): { \"goal\": \"...\", \"action\": \"...\",\n",
    "    \"conflict\": \"...\", \"outcome\": \"Disaster|Success|Unclear\" }.\n",
    "  - erac: for dramatic_sequel only (else null): { \"emotion\": \"...\", \"reason\": \"...\",\n",
    "    \"anticipation\": \"...\", \"choice\": \"...\" }.\n",
    "  - reason: 1–3 sentences explaining the label and boundary choice (focus on\n",
    "    time/place continuity and GACD/ERAC evidence).\n",
    "  - confidence: float in [0,1].\n",
    "\n",
    "Ensure segments are contiguous, non-overlapping, and collectively cover only\n",
    "the parts of the text that are actual narrative (it is okay if front/back matter\n",
    "is labeled as \"other\" and some gaps are unsegmented).\n",
    "\"\"\"\n",
    "\n",
    "SCENE_SEQUEL_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "You will receive a STORY in plain text. Segment it into COARSE narrative\n",
    "segments and label each as dramatic_scene, dramatic_sequel, narrative_scene,\n",
    "or other, following the system instructions.\n",
    "\n",
    "Procedure you MUST follow (internally):\n",
    "1) Skim the STORY to identify major time/place blocks and explicit scene-breaks.\n",
    "2) Propose initial boundaries at major time/place changes or explicit markers.\n",
    "3) Merge adjacent tiny spans (< ~3 sentences or ~100 chars) unless there is a\n",
    "   real time/place shift.\n",
    "4) Classify each final segment:\n",
    "   - dramatic_scene → find GACD evidence (goal, action, conflict, outcome).\n",
    "   - dramatic_sequel → find ERAC evidence (emotion, reason, anticipation, choice).\n",
    "   - narrative_scene → time/place unified but no clear GACD/ERAC.\n",
    "   - other → non-narrative material.\n",
    "5) Produce the JSON described in the system prompt. Use the exact schema and keys.\n",
    "\n",
    "Return ONLY JSON with this shape:\n",
    "{{\n",
    "  \"segments\": [\n",
    "    {{\n",
    "      \"segment_id\": 1,\n",
    "      \"segment_type\": \"dramatic_scene\" | \"dramatic_sequel\" | \"narrative_scene\" | \"other\",\n",
    "      \"start_char\": 0,\n",
    "      \"end_char\": 1234,\n",
    "      \"summary\": \"<≤200-char summary of the segment>\",\n",
    "      \"cohesion\": {{\n",
    "        \"time\": \"<what time unifies this segment (if stated or implied)>\",\n",
    "        \"place\": \"<what place unifies this segment (if stated or implied)>\",\n",
    "        \"characters\": [\"<main character(s)>\"]\n",
    "      }},\n",
    "      \"gacd\": {{\n",
    "        \"goal\": \"...\",\n",
    "        \"action\": \"...\",\n",
    "        \"conflict\": \"...\",\n",
    "        \"outcome\": \"Disaster|Success|Unclear\"\n",
    "      }} | null,\n",
    "      \"erac\": {{\n",
    "        \"emotion\": \"...\",\n",
    "        \"reason\": \"...\",\n",
    "        \"anticipation\": \"...\",\n",
    "        \"choice\": \"...\"\n",
    "      }} | null,\n",
    "      \"reason\": \"<why this label and these boundaries>\",\n",
    "      \"confidence\": 0.0\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "STORY:\n",
    "\\\"\\\"\\\"{story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "def make_scene_sequel_extractor(client):\n",
    "    return llm_extractor.JSONPromptExtractor(\n",
    "        client,\n",
    "        system_prompt=SCENE_SEQUEL_SYSTEM_PROMPT,\n",
    "        user_prompt_template=SCENE_SEQUEL_USER_PROMPT_TEMPLATE,\n",
    "        output_key=\"segments\",\n",
    "        default_model=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        force_json=True,\n",
    "    )\n",
    "\n",
    "revised_extractor = make_scene_sequel_extractor(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11039c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_extraction = revised_extractor.extract(example_story.body)\n",
    "revised_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_result = revised_extraction['extracted_output']\n",
    "revised_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17cfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_revised(story_text, extracted_scenes):\n",
    "    for i, scene in enumerate(extracted_scenes):\n",
    "        segment_id = scene.get('segment_id', 'unknown')\n",
    "        segment_type = scene.get('segment_type', 'unknown')\n",
    "        start_char = scene.get('start_char', -1)\n",
    "        end_char = scene.get('end_char', -1)\n",
    "        summary = scene.get('summary', '')\n",
    "        cohesion = scene.get('cohesion', {})\n",
    "        gacd = scene.get('gacd', None)\n",
    "        erac = scene.get('erac', None)\n",
    "        reason = scene.get('reason', 'unknown')\n",
    "        confidence = scene.get('confidence', -1.0)\n",
    "        print(f\"Scene {i}: Type {segment_type} (Confidence: {confidence})\")\n",
    "        print(f\" - Segmentation Rationale: {reason}\")\n",
    "        print(f\" - Summary: {summary}\")\n",
    "        print(f\" - Segment ID: {segment_id}, Chars: [{start_char}:{end_char}], Length: {end_char - start_char} chars\")\n",
    "        print(f\" - Cohesion: {cohesion}\")\n",
    "        if gacd:\n",
    "            print(f\" - GACD: {gacd}\")\n",
    "        if erac:\n",
    "            print(f\" - ERAC: {erac}\")\n",
    "        # scene_text = story_text[start_char:end_char] if 0 <= start_char < end_char <= len(story_text) else ''\n",
    "        # print(f\" - Scene Text:\")\n",
    "        # print(scene_text)\n",
    "        print()\n",
    "\n",
    "display_revised(example_story.body, revised_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example_story.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.pprint(example_story.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_SEQUEL_SYSTEM_PROMPT = \"\"\"\n",
    "You are a narrative segmentation assistant. Your job is to segment a story\n",
    "into COARSE-GRAINED, contiguous narrative segments (“scenes” at the level\n",
    "of time/place), then label each segment.\n",
    "\n",
    "### Segment Types\n",
    "- dramatic_scene: a narrative scene where a focal character with a Goal takes\n",
    "  Action, encounters Conflict, and reaches a Disaster or Success (GACD).\n",
    "- dramatic_sequel: a narrative scene (typically after a dramatic_scene) where\n",
    "  a focal character experiences Emotion, reasons about Options, Anticipates\n",
    "  outcomes, and Chooses a new goal (ERAC).\n",
    "- narrative_scene: a narrative scene unified by time/place (and often\n",
    "  character/action) but lacking clear GACD/ERAC structure.\n",
    "- other: text that is not a narrative scene (e.g., front/back matter,\n",
    "  epigraphs, meta-commentary, tables of contents, etc.).\n",
    "\n",
    "### Granularity Rules (VERY IMPORTANT)\n",
    "1) Coarse segmentation only. Prefer FEWER, LARGER segments over many small ones.\n",
    "2) Split primarily on MEANINGFUL changes in TIME and/or PLACE (or explicit\n",
    "   scene-break markers like “***”, chapter headers, clear time jumps).\n",
    "3) Do NOT split simply because a paragraph or a couple of sentences shift topic.\n",
    "   If time/place is stable, keep them in the same segment.\n",
    "4) Merge tiny candidate segments (< ~3 sentences or ~100 characters) into\n",
    "   adjacent segments unless there is an explicit time/place change.\n",
    "5) Dialogue ping-pong alone is not a boundary; treat as one scene unless\n",
    "   time/place changes.\n",
    "6) A dramatic_sequel typically follows a dramatic_scene in the SAME time/place,\n",
    "   unless the text clearly relocates the character in time/place.\n",
    "7) If unsure between dramatic_scene vs narrative_scene, choose narrative_scene.\n",
    "   If unsure between dramatic_sequel vs narrative_scene, choose narrative_scene.\n",
    "\n",
    "### Coverage & Ordering Rules\n",
    "- Ensure coverage across the entire STORY, not just the beginning. If later\n",
    "  paragraphs are narrative but do not clearly fit GACD/ERAC, label them as\n",
    "  narrative_scene (or other) rather than omitting them.\n",
    "- Segments must be in ascending order, contiguous within their own boundaries,\n",
    "  and non-overlapping. It is acceptable to include “other” segments for\n",
    "  non-narrative material.\n",
    "\n",
    "### Output Requirements (JSON ONLY)\n",
    "Return exactly one JSON object: { \"segments\": [ ... ] }\n",
    "\n",
    "For each segment include:\n",
    "- segment_id: integer index starting at 1.\n",
    "- segment_type: \"dramatic_scene\" | \"dramatic_sequel\" | \"narrative_scene\" | \"other\".\n",
    "\n",
    "# --- Robust location selectors (PRIMARY) ---\n",
    "- start_par_id: integer paragraph id where the segment begins (inclusive).\n",
    "- end_par_id: integer paragraph id where the segment ends (inclusive).\n",
    "- start_exact: the FIRST ≤120 characters of the segment, COPIED VERBATIM from the STORY text.\n",
    "- end_exact: the LAST ≤120 characters of the segment, COPIED VERBATIM from the STORY text.\n",
    "- start_prefix: ≤60 characters immediately BEFORE start_exact in the STORY (\"\" if none).\n",
    "- end_suffix: ≤60 characters immediately AFTER end_exact in the STORY (\"\" if none).\n",
    "\n",
    "Rules for anchors:\n",
    "- Copy characters EXACTLY as they appear in the STORY (whitespace/punctuation included).\n",
    "- Do NOT include paragraph id markers like [P0001] in start_exact/end_exact/prefix/suffix.\n",
    "  These markers are scaffolding, not part of the narrative text.\n",
    "\n",
    "# --- Advisory offsets (OPTIONAL) ---\n",
    "- start_char: 0-based start index into the STORY string (Python slicing) or null if unsure.\n",
    "- end_char: 0-based end index (exclusive) into the STORY or null if unsure.\n",
    "\n",
    "# --- Descriptive fields ---\n",
    "- summary: ≤200 characters summarizing the segment (not the full text).\n",
    "- cohesion: brief notes identifying the unifying TIME/PLACE/CHARACTERS.\n",
    "- gacd: for dramatic_scene only, else null:\n",
    "  { \"goal\": \"...\", \"action\": \"...\", \"conflict\": \"...\", \"outcome\": \"Disaster|Success|Unclear\" }.\n",
    "- erac: for dramatic_sequel only, else null:\n",
    "  { \"emotion\": \"...\", \"reason\": \"...\", \"anticipation\": \"...\", \"choice\": \"...\" }.\n",
    "- reason: 1–3 sentences justifying the label and boundary (refer to time/place continuity and GACD/ERAC cues).\n",
    "- confidence: float in [0,1].\n",
    "\"\"\"\n",
    "\n",
    "SCENE_SEQUEL_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "You will receive a STORY with paragraph ids embedded as markers like [P0001].\n",
    "Use paragraph ids for boundaries and supply robust text anchors as described.\n",
    "\n",
    "Procedure you MUST follow (internally):\n",
    "1) Skim the STORY to identify major time/place blocks and explicit scene-breaks.\n",
    "2) Propose initial boundaries at meaningful time/place changes or explicit markers.\n",
    "3) Merge adjacent tiny spans (< ~3 sentences or ~100 chars) unless there is a real time/place shift.\n",
    "4) Classify each final segment:\n",
    "   - dramatic_scene → find GACD evidence (goal, action, conflict, outcome).\n",
    "   - dramatic_sequel → find ERAC evidence (emotion, reason, anticipation, choice).\n",
    "   - narrative_scene → time/place unified but no clear GACD/ERAC.\n",
    "   - other → non-narrative material.\n",
    "5) Ensure later paragraphs are not omitted: if unsure, label as narrative_scene or other.\n",
    "6) Produce ONLY the JSON described in the system prompt, using the exact keys and schema.\n",
    "\n",
    "Return ONLY JSON with this shape:\n",
    "{{\n",
    "  \"segments\": [\n",
    "    {{\n",
    "      \"segment_id\": 1,\n",
    "      \"segment_type\": \"dramatic_scene\" | \"dramatic_sequel\" | \"narrative_scene\" | \"other\",\n",
    "      \"start_par_id\": 1,\n",
    "      \"end_par_id\": 3,\n",
    "      \"start_exact\": \"<first ≤120 chars of this segment, verbatim from STORY>\",\n",
    "      \"end_exact\": \"<last ≤120 chars of this segment, verbatim from STORY>\",\n",
    "      \"start_prefix\": \"<≤60 chars before start_exact or \"\">\",\n",
    "      \"end_suffix\": \"<≤60 chars after end_exact or \"\">\",\n",
    "      \"start_char\": null,\n",
    "      \"end_char\": null,\n",
    "      \"summary\": \"<≤200-char summary>\",\n",
    "      \"cohesion\": {{\n",
    "        \"time\": \"<unifying time (stated or implied)>\",\n",
    "        \"place\": \"<unifying place (stated or implied)>\",\n",
    "        \"characters\": [\"<main character(s)>\"]\n",
    "      }},\n",
    "      \"gacd\": {{\n",
    "        \"goal\": \"...\",\n",
    "        \"action\": \"...\",\n",
    "        \"conflict\": \"...\",\n",
    "        \"outcome\": \"Disaster|Success|Unclear\"\n",
    "      }} | null,\n",
    "      \"erac\": {{\n",
    "        \"emotion\": \"...\",\n",
    "        \"reason\": \"...\",\n",
    "        \"anticipation\": \"...\",\n",
    "        \"choice\": \"...\"\n",
    "      }} | null,\n",
    "      \"reason\": \"<why these boundaries/label>\",\n",
    "      \"confidence\": 0.0\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "STORY (with paragraph ids; DO NOT include [P####] markers in anchors):\n",
    "\\\"\\\"\\\"{indexed_story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "revised_extractor = llm_extractor.JSONPromptExtractor(\n",
    "    client,\n",
    "    system_prompt=SCENE_SEQUEL_SYSTEM_PROMPT,\n",
    "    user_prompt_template=SCENE_SEQUEL_USER_PROMPT_TEMPLATE,\n",
    "    output_key=\"segments\",\n",
    "    default_model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    force_json=True,\n",
    "    text_indexer=text_indexing.paragraph_text_indexer,\n",
    "    result_aligner=text_indexing.segments_result_aligner,\n",
    "    result_validator=text_indexing.segments_auditor,   # << NEW\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_extraction = revised_extractor.extract(example_story.body)\n",
    "revised_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_result = revised_extraction.get('extracted_output', \"SCENE EXTRACTION MISSING\")\n",
    "revised_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03026a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_report = revised_extraction.get('validation_report', \"VALIDATION REPORT MISSING\")\n",
    "validation_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_revised(story_text, extracted_scenes):\n",
    "    \"\"\"\n",
    "    Pretty-print segment results produced by the updated extractor.\n",
    "\n",
    "    - Uses start_char/end_char when valid.\n",
    "    - If missing/invalid, derives a best-effort span from start_exact/end_exact.\n",
    "    - Uses utils.sm for compact previews.\n",
    "    - Normalizes preview text:\n",
    "        * collapse runs of spaces to a single space\n",
    "        * single newlines -> spaces\n",
    "        * 2+ newlines -> single newline\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from lcats import utils\n",
    "\n",
    "    def _normalize_preview(s: str) -> str:\n",
    "        if not s:\n",
    "            return \"\"\n",
    "        # unify newlines\n",
    "        s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "        # mark paragraph breaks (2+ newlines)\n",
    "        s = re.sub(r\"\\n{2,}\", \"\\u2029\", s)\n",
    "        # single newlines -> spaces\n",
    "        s = s.replace(\"\\n\", \" \")\n",
    "        # collapse spaces/tabs\n",
    "        s = re.sub(r\"[ \\t\\u00A0]+\", \" \", s).strip()\n",
    "        # restore paragraph breaks to single newline\n",
    "        s = s.replace(\"\\u2029\", \"\\n\")\n",
    "        return s\n",
    "\n",
    "    def _sm_norm(s: str, limit: int) -> str:\n",
    "        return utils.sm(_normalize_preview(s or \"\"), limit=limit)\n",
    "\n",
    "    n_text = len(story_text)\n",
    "\n",
    "    for i, seg in enumerate(extracted_scenes):\n",
    "        segment_id   = seg.get(\"segment_id\", \"unknown\")\n",
    "        segment_type = seg.get(\"segment_type\", \"unknown\")\n",
    "        confidence   = seg.get(\"confidence\", -1.0)\n",
    "        reason       = seg.get(\"reason\", \"unknown\")\n",
    "        summary      = seg.get(\"summary\", \"\")\n",
    "\n",
    "        cohesion     = seg.get(\"cohesion\", {}) or {}\n",
    "        gacd         = seg.get(\"gacd\", None)\n",
    "        erac         = seg.get(\"erac\", None)\n",
    "\n",
    "        # Anchors & paragraph ids (new fields)\n",
    "        start_par_id = seg.get(\"start_par_id\", None)\n",
    "        end_par_id   = seg.get(\"end_par_id\", None)\n",
    "        start_exact  = seg.get(\"start_exact\", \"\") or \"\"\n",
    "        end_exact    = seg.get(\"end_exact\", \"\") or \"\"\n",
    "        start_prefix = seg.get(\"start_prefix\", \"\") or \"\"\n",
    "        end_suffix   = seg.get(\"end_suffix\", \"\") or \"\"\n",
    "\n",
    "        # Offsets (may be missing/invalid)\n",
    "        start_char = seg.get(\"start_char\", None)\n",
    "        end_char   = seg.get(\"end_char\", None)\n",
    "\n",
    "        def _valid_span(a, b):\n",
    "            return isinstance(a, int) and isinstance(b, int) and 0 <= a < b <= n_text\n",
    "\n",
    "        span_note = \"\"\n",
    "        if not _valid_span(start_char, end_char):\n",
    "            # Derive from anchors if possible (raw text; no normalization here)\n",
    "            s_idx = story_text.find(start_exact) if start_exact else -1\n",
    "            if s_idx != -1:\n",
    "                e_pos = story_text.find(end_exact, s_idx) if end_exact else -1\n",
    "                if e_pos != -1:\n",
    "                    start_char = s_idx\n",
    "                    end_char = e_pos + len(end_exact)\n",
    "                    if _valid_span(start_char, end_char):\n",
    "                        span_note = \" (derived from anchors)\"\n",
    "                    else:\n",
    "                        start_char = end_char = None\n",
    "                else:\n",
    "                    # fallback: partial window from start_exact\n",
    "                    if start_exact:\n",
    "                        start_char = s_idx\n",
    "                        end_char = min(n_text, s_idx + max(len(start_exact), 120))\n",
    "                        if _valid_span(start_char, end_char):\n",
    "                            span_note = \" (partial span from start_exact)\"\n",
    "                        else:\n",
    "                            start_char = end_char = None\n",
    "\n",
    "        length_str = (\n",
    "            f\"{end_char - start_char} chars\" if _valid_span(start_char, end_char) else \"unknown\"\n",
    "        )\n",
    "\n",
    "        print(f\"Segment {i}: Type {segment_type} (Confidence: {confidence})\")\n",
    "        print(f\" - Segmentation Rationale: {_sm_norm(reason, 200)}\")\n",
    "        print(f\" - Summary: {_sm_norm(summary, 200)}\")\n",
    "        print(\n",
    "            f\" - Segment ID: {segment_id}, Chars: [{start_char}:{end_char}] {span_note}, Length: {length_str}\"\n",
    "        )\n",
    "\n",
    "        # Paragraph & anchors (normalized+sm for readability)\n",
    "        print(f\" - Paragraphs: start_par_id={start_par_id}, end_par_id={end_par_id}\")\n",
    "        print(\n",
    "            \" - Anchors:\"\n",
    "            f\"\\n     start_prefix='{_sm_norm(start_prefix, 80)}'\"\n",
    "            f\"\\n     start_exact ='{_sm_norm(start_exact, 120)}'\"\n",
    "            f\"\\n     end_exact   ='{_sm_norm(end_exact, 120)}'\"\n",
    "            f\"\\n     end_suffix  ='{_sm_norm(end_suffix, 80)}'\"\n",
    "        )\n",
    "\n",
    "        # Cohesion pretty-print\n",
    "        time_ = cohesion.get(\"time\", \"\")\n",
    "        place = cohesion.get(\"place\", \"\")\n",
    "        chars = cohesion.get(\"characters\", [])\n",
    "        # Normalize the string fields for display\n",
    "        print(f\" - Cohesion: time='{_sm_norm(time_, 120)}', place='{_sm_norm(place, 120)}', characters={chars}\")\n",
    "\n",
    "        if gacd:\n",
    "            # Normalize each field of GACD for display\n",
    "            g_goal = _sm_norm((gacd or {}).get(\"goal\", \"\"), 140)\n",
    "            g_act  = _sm_norm((gacd or {}).get(\"action\", \"\"), 140)\n",
    "            g_con  = _sm_norm((gacd or {}).get(\"conflict\", \"\"), 140)\n",
    "            g_out  = (gacd or {}).get(\"outcome\", \"\")\n",
    "            print(f\" - GACD: goal='{g_goal}', action='{g_act}', conflict='{g_con}', outcome='{g_out}'\")\n",
    "        if erac:\n",
    "            e_emo = _sm_norm((erac or {}).get(\"emotion\", \"\"), 140)\n",
    "            e_rea = _sm_norm((erac or {}).get(\"reason\", \"\"), 140)\n",
    "            e_ant = _sm_norm((erac or {}).get(\"anticipation\", \"\"), 140)\n",
    "            e_cho = _sm_norm((erac or {}).get(\"choice\", \"\"), 140)\n",
    "            print(f\" - ERAC: emotion='{e_emo}', reason='{e_rea}', anticipation='{e_ant}', choice='{e_cho}'\")\n",
    "\n",
    "        # Optional: show a normalized + sm preview slice if we have a valid span\n",
    "        if _valid_span(start_char, end_char):\n",
    "            snippet = story_text[start_char:end_char]\n",
    "            print(f\" - Preview: {_normalize_preview(snippet)[:200]}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "display_revised(example_story.body, revised_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_SEMANTICS_SYSTEM_PROMPT = \"\"\"\n",
    "You are a careful analyst of narrative segments. Your task is to read ONE\n",
    "contiguous segment of a story (only the text provided) and classify it\n",
    "according to these mutually-exclusive labels:\n",
    "\n",
    "- dramatic_scene: A narrative scene with Goal–Action–Conflict–Outcome (GACD).\n",
    "  A focal character pursues a goal, acts, meets resistance, and the segment\n",
    "  reaches an outcome (Disaster or Success).\n",
    "\n",
    "- dramatic_sequel: A narrative scene typically following a dramatic scene,\n",
    "  showing Emotion–Reason–Anticipation–Choice (ERAC). The focal character reacts,\n",
    "  thinks through options, anticipates outcomes, and makes a choice/new goal.\n",
    "\n",
    "- narrative_scene: A narrative scene unified by time/place (and often characters\n",
    "  and action) but lacking clear GACD/ERAC structure.\n",
    "\n",
    "- other: Non-narrative or framing material (paratext, front/back matter, etc.)\n",
    "  or text that is not a coherent time/place scene.\n",
    "\n",
    "IMPORTANT:\n",
    "- Use ONLY the provided segment text. Ignore any external labels or metadata.\n",
    "- Prefer \"narrative_scene\" over dramatic labels when evidence is weak or partial.\n",
    "- Quote or paraphrase SHORT evidence (≤ 160 chars per item).\n",
    "- Output MUST be valid JSON and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SCENE_SEMANTICS_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Read the SEGMENT text below and return a JSON object under key \"judgment\"\n",
    "with your classification and checks. Base your decision strictly on the text.\n",
    "\n",
    "Return ONLY JSON with this shape:\n",
    "{{\n",
    "  \"judgment\": {{\n",
    "    \"label\": \"dramatic_scene\" | \"dramatic_sequel\" | \"narrative_scene\" | \"other\",\n",
    "    \"reason\": \"<2–4 sentences explaining the label; reference concrete cues>\",\n",
    "    \"confidence\": 0.0,\n",
    "    \"checks\": {{\n",
    "      \"time_place_unity\": true | false,\n",
    "      \"gacd\": {{\n",
    "        \"has_goal\": true | false,\n",
    "        \"has_action\": true | false,\n",
    "        \"has_conflict\": true | false,\n",
    "        \"outcome\": \"Disaster\" | \"Success\" | \"Unclear\" | \"None\"\n",
    "      }},\n",
    "      \"erac\": {{\n",
    "        \"has_emotion\": true | false,\n",
    "        \"has_reason\": true | false,\n",
    "        \"has_anticipation\": true | false,\n",
    "        \"has_choice\": true | false\n",
    "      }}\n",
    "    }},\n",
    "    \"evidence\": {{\n",
    "      \"time\": \"<if stated or implied, else \\\"\\\">\",\n",
    "      \"place\": \"<if stated or implied, else \\\"\\\">\",\n",
    "      \"characters\": [\"<main character(s)>\"],\n",
    "      \"quotes\": {{\n",
    "        \"goal\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"action\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"conflict\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"outcome\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"emotion\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"reason\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"anticipation\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"choice\": \"<≤160 chars or \\\"\\\">\"\n",
    "      }}\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "SEGMENT:\n",
    "\\\"\\\"\\\"{story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_scene_semantics_extractor(client: Any) -> llm_extractor.JSONPromptExtractor:\n",
    "    \"\"\"Create a JSONPromptExtractor configured for per-segment semantics.\n",
    "\n",
    "    Args:\n",
    "        client: OpenAI-like client (supports chat.completions.create).\n",
    "\n",
    "    Returns:\n",
    "        Configured JSONPromptExtractor that returns a dict under key \"judgment\".\n",
    "    \"\"\"\n",
    "    return llm_extractor.JSONPromptExtractor(\n",
    "        client=client,\n",
    "        system_prompt=SCENE_SEMANTICS_SYSTEM_PROMPT,\n",
    "        user_prompt_template=SCENE_SEMANTICS_USER_PROMPT_TEMPLATE,\n",
    "        output_key=\"judgment\",\n",
    "        default_model=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        force_json=True,\n",
    "        text_indexer=None,       # segment-level: no indexing\n",
    "        result_aligner=None,     # segment-level: no alignment\n",
    "        result_validator=None,   # optional: add later if desired\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_segment_semantics(\n",
    "    extractor: llm_extractor.JSONPromptExtractor,\n",
    "    segment_text: str,\n",
    "    model_name: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Evaluate one segment's semantics.\n",
    "\n",
    "    Args:\n",
    "        extractor: Instance returned by make_scene_semantics_extractor.\n",
    "        segment_text: The raw text of a single segment.\n",
    "        model_name: Optional model override.\n",
    "\n",
    "    Returns:\n",
    "        The extractor result dict. The semantic judgment is in\n",
    "        result['extracted_output'].\n",
    "    \"\"\"\n",
    "    return extractor(segment_text, model_name=model_name)\n",
    "\n",
    "\n",
    "def annotate_segments_with_semantics(\n",
    "    story_text: str,\n",
    "    segments: List[Dict[str, Any]],\n",
    "    extractor: llm_extractor.JSONPromptExtractor,\n",
    "    model_name: Optional[str] = None,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Attach semantic judgments to each segment dict.\n",
    "\n",
    "    Args:\n",
    "        story_text: Full canonical story text (used to slice segments).\n",
    "        segments: List of segment dicts with 'start_char'/'end_char'.\n",
    "        extractor: Instance from make_scene_semantics_extractor.\n",
    "        model_name: Optional model override.\n",
    "\n",
    "    Returns:\n",
    "        The same list with each segment augmented by a 'semantic' field:\n",
    "        segment['semantic'] = extracted judgment dict (or None on failure).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If a segment has invalid or missing offsets.\n",
    "    \"\"\"\n",
    "    n = len(story_text)\n",
    "    out: List[Dict[str, Any]] = []\n",
    "\n",
    "    for seg in segments:\n",
    "        s = seg.get(\"start_char\")\n",
    "        e = seg.get(\"end_char\")\n",
    "        if not (isinstance(s, int) and isinstance(e, int) and 0 <= s < e <= n):\n",
    "            raise ValueError(\n",
    "                f\"Segment {seg.get('segment_id', '?')} has invalid offsets: {s}, {e}\"\n",
    "            )\n",
    "        text = story_text[s:e]\n",
    "        result = extractor(text, model_name=model_name)\n",
    "        seg_copy = dict(seg)\n",
    "        seg_copy[\"segment_text\"] = text\n",
    "        seg_copy[\"segment_eval\"] = result.get(\"extracted_output\")\n",
    "        out.append(seg_copy)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_extractor = make_scene_semantics_extractor(client)\n",
    "\n",
    "annotated_segments = annotate_segments_with_semantics(\n",
    "    example_story.body,\n",
    "    revised_result,\n",
    "    semantic_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238721ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _normalize_preview(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = re.sub(r\"\\n{2,}\", \"\\u2029\", s)  # mark paragraph breaks\n",
    "    s = s.replace(\"\\n\", \" \")            # single newlines -> spaces\n",
    "    s = re.sub(r\"[ \\t\\u00A0]+\", \" \", s).strip()\n",
    "    return s.replace(\"\\u2029\", \"\\n\")\n",
    "\n",
    "def display_annotated_segments(annotated_segments: List[Dict[str, Any]]) -> None:\n",
    "    for segment in annotated_segments:\n",
    "        display_annotated_segment(segment)\n",
    "\n",
    "def display_annotated_segment(segment: Dict[str, Any]) -> None:\n",
    "    print(f\"Segment ID: {segment.get('segment_id', '?')}, Summary: {utils.sm(segment.get('summary', ''), limit=100)}\")\n",
    "    segment_type = segment.get('segment_type', 'unknown')\n",
    "    confidence = segment.get('confidence', -1.0)\n",
    "    eval = segment.get(\"segment_eval\", {})\n",
    "    if eval:\n",
    "        audited_type = eval.get('label', 'unknown')\n",
    "        audited_confidence = eval.get('confidence', -1.0)\n",
    "    else:\n",
    "        audited_type = 'N/A'\n",
    "        audited_confidence = -1.0\n",
    "    if segment_type == audited_type:\n",
    "        print(\" - MATCH: Segment type matches audited type.\")\n",
    "    else:\n",
    "        print(\" - MISMATCH: Segment type DOES NOT match audited type!\")\n",
    "    \n",
    "    print(f\" - Segment Type: {segment.get('segment_type', 'unknown')}, Confidence: {segment.get('confidence', -1.0)}\")\n",
    "    print(f\"   - Reason: {utils.sm(segment.get('reason', ''), limit=100)}\")\n",
    "    if segment.get('cohesion'):\n",
    "        print(f\"   - Cohesion: {segment.get('cohesion', {})}\")\n",
    "    if segment.get('gacd'):\n",
    "        print(f\"   - GACD: {segment.get('gacd')}\")\n",
    "    if segment.get('erac'):\n",
    "        print(f\"   - ERAC: {segment.get('erac')}\")\n",
    "\n",
    "    eval = segment.get(\"segment_eval\", {})\n",
    "    if eval:\n",
    "        label = eval.get(\"label\", \"unknown\")\n",
    "        confidence = eval.get(\"confidence\", -1.0)\n",
    "        reason = eval.get(\"reason\", \"\")\n",
    "        print(f\" - Audited Type: {label}, Confidence: {confidence}\")\n",
    "        print(f\"   - Reason: {reason}\")\n",
    "        checks = eval.get(\"checks\", {})\n",
    "        print(f\"   - Checks: {checks}\")\n",
    "        evidence = eval.get(\"evidence\", {})\n",
    "        print(f\"   - Evidence: {evidence}\")\n",
    "    segment_text = segment.get(\"segment_text\", \"\")\n",
    "    preview = utils.sm(_normalize_preview(segment_text), limit=100)\n",
    "    print(f\" - Text Preview: {preview}\")\n",
    "    print()\n",
    "\n",
    "display_annotated_segments(annotated_segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4071793",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_SEQUEL_SYSTEM_PROMPT = \"\"\"\n",
    "You are a narrative segmentation assistant. Your job is to segment a story\n",
    "into COARSE-GRAINED, contiguous narrative segments (“scenes” at the level\n",
    "of time/place), then label each segment.\n",
    "\n",
    "### Segment Types\n",
    "- dramatic_scene: a narrative scene where a focal character with a Goal takes\n",
    "  Action, encounters Conflict, and reaches a Disaster or Success (GACD).\n",
    "- dramatic_sequel: a narrative scene (typically after a dramatic_scene) where\n",
    "  a focal character experiences Emotion, reasons about Options, Anticipates\n",
    "  outcomes, and Chooses a new goal (ERAC).\n",
    "- narrative_scene: a narrative scene unified by time/place (and often\n",
    "  character/action) but lacking clear GACD/ERAC structure.\n",
    "- other: text that is not a narrative scene (e.g., front/back matter,\n",
    "  epigraphs, meta-commentary, tables of contents, etc.).\n",
    "\n",
    "### Granularity Rules (VERY IMPORTANT)\n",
    "1) Coarse segmentation only. Prefer FEWER, LARGER segments over many small ones.\n",
    "2) Split primarily on MEANINGFUL changes in TIME and/or PLACE (or explicit\n",
    "   scene-break markers like “***”, chapter headers, clear time jumps).\n",
    "3) Do NOT split simply because a paragraph or a couple of sentences shift topic.\n",
    "   If time/place is stable, keep them in the same segment.\n",
    "4) Merge tiny candidate segments (< ~3 sentences or ~100 characters) into\n",
    "   adjacent segments unless there is an explicit time/place change.\n",
    "5) Dialogue ping-pong alone is not a boundary; treat as one scene unless\n",
    "   time/place changes.\n",
    "6) A dramatic_sequel typically follows a dramatic_scene in the SAME time/place,\n",
    "   unless the text clearly relocates the character in time/place.\n",
    "7) If unsure between dramatic_scene vs dramatic_sequel, base the decision on\n",
    "   the **dominant function** of the segment (see Decision Rubric). Only if\n",
    "   neither GACD nor ERAC is sufficiently evidenced, choose narrative_scene.\n",
    "\n",
    "### Decision Rubric (apply in this order)\n",
    "A) **GACD test (dramatic_scene)**:\n",
    "   - Evidence threshold: at least 3 of {Goal, Action, Conflict, Outcome} present,\n",
    "     with **Conflict** strongly indicated; Outcome may be Disaster, Success,\n",
    "     or clear interim result **within** the segment.\n",
    "   - \"Action\" here means an on-stage attempt to achieve the Goal that meets\n",
    "     resistance. Purely logistical/administrative actions (asking directions,\n",
    "     bandaging, scheduling, riding a train) are NOT sufficient unless they are\n",
    "     the means by which the Goal is pursued and meet resistance on-stage.\n",
    "\n",
    "B) **ERAC test (dramatic_sequel)**:\n",
    "   - Evidence threshold: at least **2 of {Emotion, Reason, Anticipation, Choice}**\n",
    "     are clearly present; **AND** there is no on-stage Conflict/Outcome within\n",
    "     the segment.\n",
    "   - Typical cues: “dazed / shaken / weak”, “recalled…”, medical attention,\n",
    "     **deliberation** (“too far to go”, “I determined/decided/resolved”), planning,\n",
    "     consulting authorities (doctor/police) as **choice** rather than conflict.\n",
    "\n",
    "C) If neither threshold is met:\n",
    "   - Label **narrative_scene** when time/place unity is clear.\n",
    "   - Otherwise label **other**.\n",
    "\n",
    "### Consistency Constraints\n",
    "- If you label **dramatic_scene**:\n",
    "  - checks.gacd.has_action == true\n",
    "  - checks.gacd.has_conflict == true\n",
    "  - checks.gacd.outcome != \"None\"\n",
    "- If you label **dramatic_sequel**:\n",
    "  - At least two of {checks.erac.has_emotion, has_reason, has_anticipation, has_choice} are true.\n",
    "  - checks.gacd.has_conflict == false\n",
    "  - checks.gacd.outcome in {\"None\", \"Unclear\"}\n",
    "\n",
    "### Common Confusions to Avoid\n",
    "- **Sequel vs Narrative**: If the segment shows recovery/reaction + thinking\n",
    "  through options + a clear decision/commitment, label **dramatic_sequel**,\n",
    "  not narrative_scene.\n",
    "- **Action vs Logistics**: Asking a porter, getting treated, choosing to report,\n",
    "  or traveling are **logistical** steps; unless they meet resistance that creates\n",
    "  **Conflict** in the moment, they are **not** GACD \"Action\".\n",
    "- **Morning-after** recovery with planning is a frequent **dramatic_sequel**.\n",
    "\n",
    "### Coverage & Ordering Rules\n",
    "- Ensure coverage across the entire STORY. If later paragraphs are narrative\n",
    "  but do not fit GACD/ERAC, label them as narrative_scene (or other); do not\n",
    "  omit segments.\n",
    "- Segments must be in ascending order, contiguous within their own boundaries,\n",
    "  and non-overlapping. “Other” is acceptable for non-narrative material.\n",
    "\n",
    "### Output Requirements (JSON ONLY)\n",
    "Return exactly one JSON object: { \"segments\": [ ... ] }\n",
    "\n",
    "For each segment include:\n",
    "- segment_id: integer index starting at 1.\n",
    "- segment_type: \"dramatic_scene\" | \"dramatic_sequel\" | \"narrative_scene\" | \"other\".\n",
    "\n",
    "# --- Robust location selectors (PRIMARY) ---\n",
    "- start_par_id: integer paragraph id where the segment begins (inclusive).\n",
    "- end_par_id: integer paragraph id where the segment ends (inclusive).\n",
    "- start_exact: the FIRST ≤120 characters of the segment, COPIED VERBATIM from the STORY text.\n",
    "- end_exact: the LAST ≤120 characters of the segment, COPIED VERBATIM from the STORY text.\n",
    "- start_prefix: ≤60 characters immediately BEFORE start_exact in the STORY (\"\" if none).\n",
    "- end_suffix: ≤60 characters immediately AFTER end_exact in the STORY (\"\" if none).\n",
    "\n",
    "Rules for anchors:\n",
    "- Copy characters EXACTLY as they appear in the STORY (whitespace/punctuation included).\n",
    "- Do NOT include paragraph id markers like [P0001] in start_exact/end_exact/prefix/suffix.\n",
    "\n",
    "# --- Advisory offsets (OPTIONAL) ---\n",
    "- start_char: 0-based start index into the STORY string (Python slicing) or null if unsure.\n",
    "- end_char: 0-based end index (exclusive) into the STORY or null if unsure.\n",
    "\n",
    "# --- Descriptive fields ---\n",
    "- summary: ≤200 characters summarizing the segment (not the full text).\n",
    "- cohesion: brief notes identifying the unifying TIME/PLACE/CHARACTERS.\n",
    "- gacd: for dramatic_scene only, else null:\n",
    "  { \"goal\": \"...\", \"action\": \"...\", \"conflict\": \"...\", \"outcome\": \"Disaster|Success|Unclear\" }.\n",
    "- erac: for dramatic_sequel only, else null:\n",
    "  { \"emotion\": \"...\", \"reason\": \"...\", \"anticipation\": \"...\", \"choice\": \"...\" }.\n",
    "- reason: 1–3 sentences justifying the label and boundary (refer to time/place continuity\n",
    "  and **Decision Rubric** evidence).\n",
    "- confidence: float in [0,1].\n",
    "\"\"\"\n",
    "\n",
    "scene_extractor = llm_extractor.JSONPromptExtractor(\n",
    "    client,\n",
    "    system_prompt=SCENE_SEQUEL_SYSTEM_PROMPT,\n",
    "    user_prompt_template=SCENE_SEQUEL_USER_PROMPT_TEMPLATE,\n",
    "    output_key=\"segments\",\n",
    "    default_model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    force_json=True,\n",
    "    text_indexer=text_indexing.paragraph_text_indexer,\n",
    "    result_aligner=text_indexing.segments_result_aligner,\n",
    "    result_validator=text_indexing.segments_auditor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prompts for per-segment semantic auditing/classification.\"\"\"\n",
    "\n",
    "SCENE_SEMANTICS_SYSTEM_PROMPT = \"\"\"\n",
    "You are a careful analyst of narrative segments. Your task is to read ONE\n",
    "contiguous segment of a story (only the text provided) and classify it into\n",
    "exactly one of:\n",
    "\n",
    "- dramatic_scene: A narrative scene with Goal–Action–Conflict–Outcome (GACD).\n",
    "  A focal character pursues a goal, acts, meets resistance, and the segment\n",
    "  itself reaches an outcome (Disaster or Success).\n",
    "\n",
    "- dramatic_sequel: A narrative scene (typically after a dramatic scene),\n",
    "  showing Emotion–Reason–Anticipation–Choice (ERAC). The focal character reacts,\n",
    "  thinks through options, anticipates outcomes, and makes a choice/new goal.\n",
    "\n",
    "- narrative_scene: A narrative scene unified by time/place (and often\n",
    "  characters/action) but lacking clear GACD/ERAC structure.\n",
    "\n",
    "- other: Non-narrative or framing material (paratext, front/back matter, etc.)\n",
    "  or text that is not a coherent time/place scene.\n",
    "\n",
    "IMPORTANT:\n",
    "- Use ONLY the provided segment text. Ignore any external labels or metadata.\n",
    "- Quote or paraphrase SHORT evidence (≤ 160 chars each). Prefer quotes when\n",
    "  possible; paraphrase only if exact phrasing is too long.\n",
    "\n",
    "DECISION RUBRIC (apply in this order)\n",
    "A) GACD → dramatic_scene\n",
    "   • Threshold: at least 3 of {{Goal, Action, Conflict, Outcome}} present,\n",
    "     with Conflict clearly on-stage; an Outcome occurs **within this segment**.\n",
    "   • \"Action\" means an on-stage attempt to achieve the Goal that meets\n",
    "     resistance. Purely logistical/administrative steps (asking a porter,\n",
    "     bandaging, scheduling, riding a train) are NOT sufficient unless they are\n",
    "     the means to the Goal and meet resistance on-stage.\n",
    "\n",
    "B) ERAC → dramatic_sequel\n",
    "   • Threshold: at least 2 of {{Emotion, Reason, Anticipation, Choice}} present,\n",
    "     AND no on-stage Conflict/Outcome inside the segment.\n",
    "   • Typical cues: recovery or instability (dazed/weak), recalling events,\n",
    "     deliberation about options/costs/risks (“too far to go”), and a decision\n",
    "     or commitment (“I determined/decided…”).\n",
    "\n",
    "C) If neither threshold is met:\n",
    "   • Label narrative_scene if time/place unity is clear.\n",
    "   • Otherwise label other.\n",
    "\n",
    "CONSISTENCY CONSTRAINTS (must hold)\n",
    "- If label == dramatic_scene:\n",
    "  • checks.gacd.has_action == true\n",
    "  • checks.gacd.has_conflict == true\n",
    "  • checks.gacd.outcome in {{ \"Disaster\", \"Success\", \"Unclear\" }} (not \"None\")\n",
    "  • At least one GACD evidence quote present.\n",
    "- If label == dramatic_sequel:\n",
    "  • At least two of {{checks.erac.has_emotion, has_reason, has_anticipation,\n",
    "    has_choice}} are true.\n",
    "  • checks.gacd.has_conflict == false\n",
    "  • checks.gacd.outcome in {{ \"None\", \"Unclear\" }}\n",
    "  • At least one ERAC evidence quote present.\n",
    "\n",
    "COMMON CONFUSIONS TO AVOID\n",
    "- Sequel vs Narrative: Recovery + deliberation + decision/commitment is\n",
    "  dramatic_sequel, not narrative_scene.\n",
    "- Action vs Logistics: Asking directions, medical care, or routine travel is\n",
    "  **logistical** unless it meets resistance that creates conflict in the moment.\n",
    "- \"Morning-after\" recovery with planning typically indicates dramatic_sequel.\n",
    "\n",
    "OUTPUT POLICY\n",
    "- Return ONLY valid JSON (no prose outside JSON). Keep evidence fields ≤ 160\n",
    "  chars each. Do not fabricate conflict/outcome if none occurs on-stage.\n",
    "\"\"\"\n",
    "\n",
    "SCENE_SEMANTICS_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Read the SEGMENT text below and return a JSON object under key \"judgment\"\n",
    "with your classification and checks. Base your decision strictly on the text.\n",
    "Apply the Decision Rubric and enforce the Consistency Constraints.\n",
    "\n",
    "Return ONLY JSON with this shape:\n",
    "{{\n",
    "  \"judgment\": {{\n",
    "    \"label\": \"dramatic_scene\" | \"dramatic_sequel\" | \"narrative_scene\" | \"other\",\n",
    "    \"reason\": \"<2–4 sentences explaining the label; cite concrete cues>\",\n",
    "    \"confidence\": 0.0,\n",
    "    \"checks\": {{\n",
    "      \"time_place_unity\": true | false,\n",
    "      \"gacd\": {{\n",
    "        \"has_goal\": true | false,\n",
    "        \"has_action\": true | false,\n",
    "        \"has_conflict\": true | false,\n",
    "        \"outcome\": \"Disaster\" | \"Success\" | \"Unclear\" | \"None\"\n",
    "      }},\n",
    "      \"erac\": {{\n",
    "        \"has_emotion\": true | false,\n",
    "        \"has_reason\": true | false,\n",
    "        \"has_anticipation\": true | false,\n",
    "        \"has_choice\": true | false\n",
    "      }}\n",
    "    }},\n",
    "    \"evidence\": {{\n",
    "      \"time\": \"<if stated or implied, else \\\"\\\">\",\n",
    "      \"place\": \"<if stated or implied, else \\\"\\\">\",\n",
    "      \"characters\": [\"<main character(s)>\"],\n",
    "      \"quotes\": {{\n",
    "        \"goal\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"action\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"conflict\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"outcome\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"emotion\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"reason\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"anticipation\": \"<≤160 chars or \\\"\\\">\",\n",
    "        \"choice\": \"<≤160 chars or \\\"\\\">\"\n",
    "      }}\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "SEGMENT:\n",
    "\\\"\\\"\\\"{story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "def make_scene_semantics_extractor(client: Any) -> llm_extractor.JSONPromptExtractor:\n",
    "    \"\"\"Create a JSONPromptExtractor configured for per-segment semantics.\n",
    "\n",
    "    Args:\n",
    "        client: OpenAI-like client (supports chat.completions.create).\n",
    "\n",
    "    Returns:\n",
    "        Configured JSONPromptExtractor that returns a dict under key \"judgment\".\n",
    "    \"\"\"\n",
    "    return llm_extractor.JSONPromptExtractor(\n",
    "        client=client,\n",
    "        system_prompt=SCENE_SEMANTICS_SYSTEM_PROMPT,\n",
    "        user_prompt_template=SCENE_SEMANTICS_USER_PROMPT_TEMPLATE,\n",
    "        output_key=\"judgment\",\n",
    "        default_model=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        force_json=True,\n",
    "        text_indexer=None,       # segment-level: no indexing\n",
    "        result_aligner=None,     # segment-level: no alignment\n",
    "        result_validator=None,   # optional: add later if desired\n",
    "    )\n",
    "\n",
    "semantic_extractor = make_scene_semantics_extractor(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_segments(story_text, extracted_scenes):\n",
    "    \"\"\"\n",
    "    Pretty-print segment results produced by the updated extractor.\n",
    "\n",
    "    - Uses start_char/end_char when valid.\n",
    "    - If missing/invalid, derives a best-effort span from start_exact/end_exact.\n",
    "    - Uses utils.sm for compact previews.\n",
    "    - Normalizes preview text:\n",
    "        * collapse runs of spaces to a single space\n",
    "        * single newlines -> spaces\n",
    "        * 2+ newlines -> single newline\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from lcats import utils\n",
    "\n",
    "    def _normalize_preview(s: str) -> str:\n",
    "        if not s:\n",
    "            return \"\"\n",
    "        # unify newlines\n",
    "        s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "        # mark paragraph breaks (2+ newlines)\n",
    "        s = re.sub(r\"\\n{2,}\", \"\\u2029\", s)\n",
    "        # single newlines -> spaces\n",
    "        s = s.replace(\"\\n\", \" \")\n",
    "        # collapse spaces/tabs\n",
    "        s = re.sub(r\"[ \\t\\u00A0]+\", \" \", s).strip()\n",
    "        # restore paragraph breaks to single newline\n",
    "        s = s.replace(\"\\u2029\", \"\\n\")\n",
    "        return s\n",
    "\n",
    "    def _sm_norm(s: str, limit: int) -> str:\n",
    "        return utils.sm(_normalize_preview(s or \"\"), limit=limit)\n",
    "\n",
    "    n_text = len(story_text)\n",
    "\n",
    "    for i, seg in enumerate(extracted_scenes):\n",
    "        segment_id   = seg.get(\"segment_id\", \"unknown\")\n",
    "        segment_type = seg.get(\"segment_type\", \"unknown\")\n",
    "        confidence   = seg.get(\"confidence\", -1.0)\n",
    "        reason       = seg.get(\"reason\", \"unknown\")\n",
    "        summary      = seg.get(\"summary\", \"\")\n",
    "\n",
    "        cohesion     = seg.get(\"cohesion\", {}) or {}\n",
    "        gacd         = seg.get(\"gacd\", None)\n",
    "        erac         = seg.get(\"erac\", None)\n",
    "\n",
    "        # Anchors & paragraph ids (new fields)\n",
    "        start_par_id = seg.get(\"start_par_id\", None)\n",
    "        end_par_id   = seg.get(\"end_par_id\", None)\n",
    "        start_exact  = seg.get(\"start_exact\", \"\") or \"\"\n",
    "        end_exact    = seg.get(\"end_exact\", \"\") or \"\"\n",
    "        start_prefix = seg.get(\"start_prefix\", \"\") or \"\"\n",
    "        end_suffix   = seg.get(\"end_suffix\", \"\") or \"\"\n",
    "\n",
    "        # Offsets (may be missing/invalid)\n",
    "        start_char = seg.get(\"start_char\", None)\n",
    "        end_char   = seg.get(\"end_char\", None)\n",
    "\n",
    "        def _valid_span(a, b):\n",
    "            return isinstance(a, int) and isinstance(b, int) and 0 <= a < b <= n_text\n",
    "\n",
    "        span_note = \"\"\n",
    "        if not _valid_span(start_char, end_char):\n",
    "            # Derive from anchors if possible (raw text; no normalization here)\n",
    "            s_idx = story_text.find(start_exact) if start_exact else -1\n",
    "            if s_idx != -1:\n",
    "                e_pos = story_text.find(end_exact, s_idx) if end_exact else -1\n",
    "                if e_pos != -1:\n",
    "                    start_char = s_idx\n",
    "                    end_char = e_pos + len(end_exact)\n",
    "                    if _valid_span(start_char, end_char):\n",
    "                        span_note = \" (derived from anchors)\"\n",
    "                    else:\n",
    "                        start_char = end_char = None\n",
    "                else:\n",
    "                    # fallback: partial window from start_exact\n",
    "                    if start_exact:\n",
    "                        start_char = s_idx\n",
    "                        end_char = min(n_text, s_idx + max(len(start_exact), 120))\n",
    "                        if _valid_span(start_char, end_char):\n",
    "                            span_note = \" (partial span from start_exact)\"\n",
    "                        else:\n",
    "                            start_char = end_char = None\n",
    "\n",
    "        length_str = (\n",
    "            f\"{end_char - start_char} chars\" if _valid_span(start_char, end_char) else \"unknown\"\n",
    "        )\n",
    "\n",
    "        print(f\"Segment {i}: Type {segment_type} (Confidence: {confidence})\")\n",
    "        print(f\" - Segmentation Rationale: {_sm_norm(reason, 200)}\")\n",
    "        print(f\" - Summary: {_sm_norm(summary, 200)}\")\n",
    "        print(\n",
    "            f\" - Segment ID: {segment_id}, Chars: [{start_char}:{end_char}] {span_note}, Length: {length_str}\"\n",
    "        )\n",
    "\n",
    "        # Paragraph & anchors (normalized+sm for readability)\n",
    "        print(f\" - Paragraphs: start_par_id={start_par_id}, end_par_id={end_par_id}\")\n",
    "        print(\n",
    "            \" - Anchors:\"\n",
    "            f\"\\n     start_prefix='{_sm_norm(start_prefix, 80)}'\"\n",
    "            f\"\\n     start_exact ='{_sm_norm(start_exact, 120)}'\"\n",
    "            f\"\\n     end_exact   ='{_sm_norm(end_exact, 120)}'\"\n",
    "            f\"\\n     end_suffix  ='{_sm_norm(end_suffix, 80)}'\"\n",
    "        )\n",
    "\n",
    "        # Cohesion pretty-print\n",
    "        time_ = cohesion.get(\"time\", \"\")\n",
    "        place = cohesion.get(\"place\", \"\")\n",
    "        chars = cohesion.get(\"characters\", [])\n",
    "        # Normalize the string fields for display\n",
    "        print(f\" - Cohesion: time='{_sm_norm(time_, 120)}', place='{_sm_norm(place, 120)}', characters={chars}\")\n",
    "\n",
    "        if gacd:\n",
    "            # Normalize each field of GACD for display\n",
    "            g_goal = _sm_norm((gacd or {}).get(\"goal\", \"\"), 140)\n",
    "            g_act  = _sm_norm((gacd or {}).get(\"action\", \"\"), 140)\n",
    "            g_con  = _sm_norm((gacd or {}).get(\"conflict\", \"\"), 140)\n",
    "            g_out  = (gacd or {}).get(\"outcome\", \"\")\n",
    "            print(f\" - GACD: goal='{g_goal}', action='{g_act}', conflict='{g_con}', outcome='{g_out}'\")\n",
    "        if erac:\n",
    "            e_emo = _sm_norm((erac or {}).get(\"emotion\", \"\"), 140)\n",
    "            e_rea = _sm_norm((erac or {}).get(\"reason\", \"\"), 140)\n",
    "            e_ant = _sm_norm((erac or {}).get(\"anticipation\", \"\"), 140)\n",
    "            e_cho = _sm_norm((erac or {}).get(\"choice\", \"\"), 140)\n",
    "            print(f\" - ERAC: emotion='{e_emo}', reason='{e_rea}', anticipation='{e_ant}', choice='{e_cho}'\")\n",
    "\n",
    "        # Optional: show a normalized + sm preview slice if we have a valid span\n",
    "        if _valid_span(start_char, end_char):\n",
    "            snippet = story_text[start_char:end_char]\n",
    "            print(f\" - Preview: {_normalize_preview(snippet)[:200]}\")\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eff01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_result = scene_extractor.extract(example_story.body)\n",
    "extracted_scenes = extraction_result.get('extracted_output', \"SCENE EXTRACTION MISSING\")\n",
    "validation_report = extraction_result.get('validation_report', \"VALIDATION REPORT MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Extracted Scenes: {len(extracted_scenes) if isinstance(extracted_scenes, list) else 'N/A'}\")\n",
    "print(f\"Validation Report:\")\n",
    "validation_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_segments(example_story.body, extracted_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_scenes = annotate_segments_with_semantics(\n",
    "    example_story.body,\n",
    "    extracted_scenes,\n",
    "    semantic_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_annotated_segments(annotated_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d395f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c66ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCATS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
