{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reboot of LCATS Story Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import date\n",
    "from typing import List, Dict, Callable, Optional\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third-party modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add imports from within the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path so we can import modules from the parent directory.\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lcats import chunking\n",
    "from lcats import extraction\n",
    "from lcats import stories\n",
    "from lcats import utils\n",
    "from lcats.datasets import torchdata\n",
    "from lcats.gatherers import extractors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the following code is run from lcats/notebooks in VSCode and the data is in lcats/data ...\n",
    "CURRENT_PATH = os.path.abspath(os.curdir)  # This is where the notebook is executing.\n",
    "PROJECT_ROOT = os.path.dirname(CURRENT_PATH)   # This should be the root of the project.\n",
    "DEV_CORPUS = os.path.abspath(os.path.join(PROJECT_ROOT, 'data'))  # Local copy of the data.\n",
    "DEV_OUTPUT = os.path.abspath(os.path.join(PROJECT_ROOT, 'output'))  # Local copy of the data.\n",
    "GIT_CORPUS = os.path.abspath(os.path.join(PROJECT_ROOT, '../corpora'))  # Data in the git repo.\n",
    "OPENIA_API_KEYS_ENV = os.path.abspath(os.path.join(PROJECT_ROOT, '../.secrets/openai_api_keys.env'))  # Local OpenAI API key.\n",
    "\n",
    "def check_path(path, description):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found {description} at: {path}\")\n",
    "    else:\n",
    "        print(f\"Missing {description} from: {path}\")\n",
    "\n",
    "check_path(DEV_CORPUS, \"DEV_CORPUS\")\n",
    "check_path(DEV_OUTPUT, \"DEV_OUTPUT\")\n",
    "check_path(GIT_CORPUS, \"GIT_CORPUS\")\n",
    "check_path(OPENIA_API_KEYS_ENV, \"OPENIA_API_KEYS_ENV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(OPENIA_API_KEYS_ENV)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that we can get a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "print(f\"Loaded OpenAI client: {client} with version: {client._version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the API is working. This week. And that you have credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a one-sentence bedtime story about a starship captain visiting a planet.\"\n",
    ")\n",
    "\n",
    "print(f\"Story generated on: {date.today()}:\")\n",
    "utils.pprint(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the modules to ensure we have the latest code, if doing active development.\n",
    "if False: \n",
    "    from importlib import reload\n",
    "    reload(stories)\n",
    "    reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run from within a notebook, the corpora root is two paths up from the notebook's location.\n",
    "CORPORA_ROOT = GIT_CORPUS  # Checked-in corpora\n",
    "# CORPORA_ROOT = DEV_CORPUS  # Command line working corpora\n",
    "\n",
    "# Now load the corpora\n",
    "corpora = stories.Corpora(CORPORA_ROOT)\n",
    "\n",
    "print(\"Loaded corpora:\")\n",
    "print(f\" - root: {corpora.corpora_root}\")\n",
    "print(f\" - corpora: {len(corpora.corpora)}\")\n",
    "print(f\" - stories: {len(corpora.stories)}\")\n",
    "print()\n",
    "print(f\"Example story: corpora.stories[0]:\")\n",
    "print(corpora.stories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_story = corpora.stories[0]\n",
    "print(f\"Story type: {type(example_story)} with a body of {len(example_story.body)} characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene and Sequel Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First-pass Prompts suggested by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_SEQUEL_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that breaks down stories into structured events.\n",
    "Each event is labeled as \"scene\", \"sequel\", or \"none\" (if it doesn't fit exactly).\n",
    "Follow these definitions:\n",
    "\n",
    "- scene: a segment where a character with a goal attempts to achieve it, leading to success or disaster.\n",
    "- sequel: a segment after a disaster or success, where a character reacts, processes emotions, considers options, and forms a new goal.\n",
    "\n",
    "Your output MUST be valid JSON and only the JSON without any other text or comments.\n",
    "\"\"\"\n",
    "\n",
    "SCENE_SEQUEL_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "I will give you a story in plain text.\n",
    "1. Read the story carefully.\n",
    "2. Identify major events or paragraphs that qualify as scenes or sequels (or 'none' if it doesn't clearly fit).\n",
    "3. For each event, provide:\n",
    "   - event_text: the text snippet or summary\n",
    "   - event_type: 'scene' or 'sequel' or 'none'\n",
    "   - reason: a short explanation of why you classified it that way\n",
    "4. Return a JSON dictionary with one key named \"events\" - the output must be valid JSON and only the JSON.\n",
    "Your output MUST be valid JSON and only the JSON without any other text or comments.\n",
    "\n",
    "STORY:\n",
    "\\\"\\\"\\\"{story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "SCENE_SEQUEL_EXTRACTOR = extraction.ExtractionTemplate(\n",
    "    name=\"scene_sequel_extractor\",\n",
    "    system_template=SCENE_SEQUEL_SYSTEM_PROMPT,\n",
    "    user_template=SCENE_SEQUEL_USER_PROMPT_TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = SCENE_SEQUEL_EXTRACTOR.build_prompt(example_story.body)\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scenes_and_sequels(\n",
    "        story_text: str,        \n",
    "        model_name: str = \"gpt-4o\",\n",
    "        temperature: float = 0.2,\n",
    "        template: Callable = SCENE_SEQUEL_EXTRACTOR,\n",
    "    ) -> extraction.ExtractionResult:\n",
    "    \"\"\"\n",
    "    Extract scenes and sequels from a story using the specified model.\n",
    "    \n",
    "    Args:\n",
    "        story_text (str): The text of the story to analyze.\n",
    "        model_name (str): The name of the OpenAI model to use for extraction.\n",
    "    \n",
    "    Returns:\n",
    "        extraction.ExtractionResult: The result of the extraction, including parsed output and any errors.\n",
    "    \"\"\"\n",
    "    return extraction.extract_from_story(\n",
    "        story_text,\n",
    "        template=template,\n",
    "        client=client,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gpt_35_turbo = extract_scenes_and_sequels(example_story.body, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_gpt_35_turbo.extracted_output), result_gpt_35_turbo.extracted_output[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this cell takes 30-90 seconds and is an expensive GPT 4.0 call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gpt_4o = extract_scenes_and_sequels(example_story.body, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_gpt_4o.extracted_output), result_gpt_4o.extracted_output[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Extractions to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_serializable(result, nonserializable_key=\"response\"):\n",
    "    \"\"\"\n",
    "    Remove a non-serializable key from the result dictionary.\n",
    "\n",
    "    Args:\n",
    "        result (dict): The dictionary to clean.\n",
    "        nonserializable_key (str): The key to remove if present.\n",
    "\n",
    "    Returns:\n",
    "        dict: A shallow copy of the dictionary with the specified key removed.\n",
    "    \"\"\"\n",
    "    result = dict(result)  # shallow copy to avoid mutating original\n",
    "    result.pop(nonserializable_key, None)\n",
    "    return result\n",
    "\n",
    "def extract_all_and_write(corpora, extractor, model_name, output_dir, file_namer, serializer):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create a subdirectory for the model\n",
    "    model_dir = os.path.join(output_dir, \"scene_extraction\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    for story in corpora.stories:\n",
    "        filename = file_namer(story.name) + \"-scenes.json\"\n",
    "        filepath = os.path.join(model_dir, filename)\n",
    "\n",
    "        # Skip already-processed files\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"Skipping already processed story: {story.name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"Processing story: {story.name}\")\n",
    "            result = extractor(story.body, model_name=model_name)\n",
    "            serialized_result = serializer(result)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                json.dump(serialized_result, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {story.name}: {e}\")\n",
    "\n",
    "    print(\"Scene extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Scenes for Two Popular Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_all_and_write(\n",
    "    corpora,\n",
    "    extract_scenes_and_sequels,\n",
    "    model_name=\"gpt-4o\",\n",
    "    output_dir=DEV_OUTPUT,\n",
    "    file_namer=extractors.title_to_filename,\n",
    "    serializer=make_serializable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_all_and_write(\n",
    "    corpora,\n",
    "    extract_scenes_and_sequels,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    output_dir=DEV_OUTPUT,\n",
    "    file_namer=extractors.title_to_filename,\n",
    "    serializer=make_serializable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Extraction, Computing if Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_story_extraction(\n",
    "    story,\n",
    "    model_name,\n",
    "    output_dir,\n",
    "    file_namer\n",
    "    ):\n",
    "    # Determine file path\n",
    "    model_dir = os.path.join(output_dir, \"scene_extraction\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    filename = file_namer(story.name) + \"-scenes.json\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "\n",
    "    # If the file exists and we're not forcing recomputation, load and return\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "def fetch_or_compute_story_extraction(\n",
    "    story,\n",
    "    extractor,\n",
    "    model_name,\n",
    "    output_dir,\n",
    "    file_namer,\n",
    "    serializer,\n",
    "    force=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch the scene/sequel extraction for a story, loading from disk if available,\n",
    "    or computing and saving it otherwise.\n",
    "\n",
    "    Parameters:\n",
    "        story: A Story object with a .name and .body attribute.\n",
    "        extractor: Function that extracts structured data from story.body.\n",
    "        model_name: Name of the model used for the extraction (e.g., 'gpt-4o').\n",
    "        output_dir: Root directory where extractions are stored.\n",
    "        file_namer: Function to turn a story name into a safe filename.\n",
    "        serializer: Function that removes or transforms non-serializable objects in the result.\n",
    "        force: If True, reprocess the story even if a saved result exists.\n",
    "\n",
    "    Returns:\n",
    "        The structured extraction result (as loaded from JSON).\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine file path\n",
    "    model_dir = os.path.join(output_dir, \"scene_extraction\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    filename = file_namer(story.name) + \"-scenes.json\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "\n",
    "    # If the file exists and we're not forcing recomputation, load and return\n",
    "    if not force and os.path.exists(filepath):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    # Otherwise compute, serialize, save, and return\n",
    "    result = extractor(story.body, model_name=model_name)\n",
    "    serializable_result = serializer(result)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(serializable_result, f, indent=2)\n",
    "    return serializable_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_story = corpora.stories[0]\n",
    "example_extraction = fetch_story_extraction(\n",
    "    example_story,\n",
    "    model_name=\"gpt-4o\",\n",
    "    output_dir=DEV_OUTPUT,\n",
    "    file_namer=extractors.title_to_filename,\n",
    ")\n",
    "len(example_extraction['parsed_output']['events'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the First Pass Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str, model: str = \"gpt-3.5-turbo\") -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def collate_story_extractions(corpora, model_name, output_dir):\n",
    "    \"\"\"\n",
    "    Collate the story extractions into a DataFrame.\n",
    "    \"\"\"\n",
    "    extractions = {}\n",
    "    statistics = []\n",
    "    for story in corpora.stories:\n",
    "        # Get metadata about the story\n",
    "        story_text = story.body\n",
    "        characters = len(story_text)\n",
    "        tokens = count_tokens(story_text, model_name)\n",
    "\n",
    "        # Get the extraction for the story\n",
    "        extraction = fetch_story_extraction(\n",
    "            story,\n",
    "            model_name=model_name,\n",
    "            output_dir=output_dir,\n",
    "            file_namer=extractors.title_to_filename,\n",
    "        )\n",
    "        extractions[story.name] = extraction\n",
    "        if extraction is None:\n",
    "            # print(f\"Missing extraction for story: {story.name}\")\n",
    "            parsed = False\n",
    "            events = []\n",
    "            scenes = []\n",
    "            sequels = []\n",
    "            nones = []\n",
    "        else:\n",
    "            # print(f\"Processing extraction for story: {story.name}\")\n",
    "            parsed = True\n",
    "            events = extraction['parsed_output']['events']\n",
    "            scenes = [e for e in events if e['event_type'] == 'scene']\n",
    "            sequels = [e for e in events if e['event_type'] == 'sequel']\n",
    "            nones = [e for e in events if e['event_type'] == 'none']\n",
    "\n",
    "        # Append the statistics for this story\n",
    "        statistics.append({\n",
    "            \"story_name\": story.name,\n",
    "            \"characters\": characters,\n",
    "            \"tokens\": tokens,\n",
    "            \"parsed\": int(parsed),\n",
    "            \"events\": len(events),\n",
    "            \"scenes\": len(scenes),\n",
    "            \"sequels\": len(sequels),\n",
    "            \"nones\": len(nones)\n",
    "        })\n",
    "    return extractions, pd.DataFrame(statistics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_data, gpt_4o_df = collate_story_extractions(\n",
    "    corpora,\n",
    "    model_name=\"gpt-4o\",\n",
    "    output_dir=DEV_OUTPUT,\n",
    ")\n",
    "print(gpt_4o_df.describe())\n",
    "gpt_4o_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_35_data, gpt_35_df = collate_story_extractions(\n",
    "    corpora,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    output_dir=DEV_OUTPUT,\n",
    ")\n",
    "print(gpt_35_df.describe())\n",
    "gpt_35_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_df[gpt_4o_df[\"story_name\"] == \"Sherlock Holmes - The Adventure of the Engineer's Thumb\"][\"tokens\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = []\n",
    "for story in corpora.stories:\n",
    "    gpt_4o_extraction = gpt_4o_data[story.name]\n",
    "    gpt_35_extraction = gpt_35_data[story.name]\n",
    "    if gpt_4o_extraction is None or gpt_35_extraction is None:\n",
    "        continue\n",
    "    gpt_4o_tokens = gpt_4o_df[gpt_4o_df[\"story_name\"] == story.name]['tokens'].values[0]\n",
    "    gpt_35_tokens = gpt_35_df[gpt_35_df[\"story_name\"] == story.name]['tokens'].values[0]\n",
    "    gpt_4o_events = gpt_4o_extraction['parsed_output']['events']\n",
    "    gpt_35_events = gpt_35_extraction['parsed_output']['events']\n",
    "    gpt_4o_scenes = [e for e in gpt_4o_events if e['event_type'] == 'scene']\n",
    "    gpt_35_scenes = [e for e in gpt_35_events if e['event_type'] == 'scene']\n",
    "    gpt_4o_sequels = [e for e in gpt_4o_events if e['event_type'] == 'sequel']\n",
    "    gpt_35_sequels = [e for e in gpt_35_events if e['event_type'] == 'sequel']\n",
    "    gpt_4o_nones = [e for e in gpt_4o_events if e['event_type'] == 'none']\n",
    "    gpt_35_nones = [e for e in gpt_35_events if e['event_type'] == 'none']\n",
    "    print(f\"Story: {story.name}\")\n",
    "    print(f\" - characters: {len(story.body)}\")\n",
    "    print(f\" - tokens: {gpt_4o_tokens} (gpt-4o) vs {gpt_35_tokens} (gpt-3.5-turbo)\")\n",
    "    print(f\" - events: {len(gpt_4o_events)} (gpt-4o) vs {len(gpt_35_events)} (gpt-3.5-turbo)\")\n",
    "    print(f\" - scenes: {len(gpt_4o_scenes)} (gpt-4o) vs {len(gpt_35_scenes)} (gpt-3.5-turbo)\")\n",
    "    print(f\" - sequels: {len(gpt_4o_sequels)} (gpt-4o) vs {len(gpt_35_sequels)} (gpt-3.5-turbo)\")\n",
    "    print(f\" - nones: {len(gpt_4o_nones)} (gpt-4o) vs {len(gpt_35_nones)} (gpt-3.5-turbo)\")\n",
    "    comparisons.append({\n",
    "        \"story_name\": story.name,\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"tokens\": gpt_4o_tokens,\n",
    "        \"events\": len(gpt_4o_events),\n",
    "        \"scenes\": len(gpt_4o_scenes),\n",
    "        \"sequels\": len(gpt_4o_sequels),\n",
    "        \"nones\": len(gpt_4o_nones)\n",
    "    })\n",
    "    comparisons.append({\n",
    "        \"story_name\": story.name,\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"tokens\": gpt_35_tokens,\n",
    "        \"events\": len(gpt_35_events),\n",
    "        \"scenes\": len(gpt_35_scenes),\n",
    "        \"sequels\": len(gpt_35_sequels),\n",
    "        \"nones\": len(gpt_35_nones)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison_df.columns)\n",
    "print(comparison_df.describe())\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_4o = gpt_4o_df[gpt_35_df[\"parsed\"] == 1]\n",
    "common_35 = gpt_35_df[gpt_35_df[\"parsed\"] == 1]\n",
    "print(\"Common stories with valid extractions:\")\n",
    "print(f\" - gpt-4o: {len(common_4o)}\")\n",
    "print(common_4o.describe())\n",
    "print(f\" - gpt-3.5-turbo: {len(common_35)}\")\n",
    "print(common_35.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_data[example_story.name]['parsed_output']['events'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_35_data[example_story.name]['parsed_output']['events'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_columns_vs(df, x_col, y_col, hue_col=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df, x=x_col, y=y_col, hue=hue_col)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(f\"{y_col} vs {x_col}\")\n",
    "    plt.legend(title=hue_col)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_columns_vs(comparison_df, 'tokens', 'events', hue_col='model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_columns_vs(comparison_df, 'tokens', 'scenes', hue_col='model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_columns_vs(comparison_df, 'tokens', 'nones', hue_col='model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Narrative Scene Extraction\n",
    "Let's try just identifying the narrative scenes proper, regardless of whether they are dramatic scenes or sequels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "NARRATIVE_SCENE_SYSTEM_PROMPT = \"\"\"You are a helpful assistant trained in analyzing narrative texts. Your task is to identify narrative scenes — contiguous segments of story that form coherent narrative units.\n",
    "\n",
    "A **narrative scene** is a portion of text that is unified by time, space, characters, and action. Scenes usually involve the same location and characters, and follow continuous or causally related events, often sharing thematic or stylistic unity (dialogue, tone, etc.).\n",
    "\n",
    "Scenes are separated by **narrative discontinuities**, such as shifts in time, space, character group, point of view, or event structure.\n",
    "\n",
    "Use the following rules to help identify scenes:\n",
    "- A scene generally takes place in one continuous time and place.\n",
    "- A scene features a coherent group of characters engaged in related actions.\n",
    "- A shift in time, location, or character group likely signals the end of a scene.\n",
    "- Brief non-narrative passages (e.g. exposition or reflection) may be labeled as 'none' unless tightly integrated.\n",
    "\n",
    "Your output must be valid JSON with one top-level key: `\"events\"`, containing a list of scenes or other segments.\n",
    "\"\"\"\n",
    "\n",
    "NARRATIVE_SCENE_USER_PROMPT = \"\"\"\n",
    "I will give you a story in plain text.\n",
    "\n",
    "1. Read the story carefully.\n",
    "2. Divide it into **narrative scenes**, using the definition and criteria provided.\n",
    "3. For each segment, provide:\n",
    "   - type: 'scene' if it is a narrative scene, 'none' if it is non-narrative material\n",
    "   - text: the full passage that constitutes the segment\n",
    "   - reason: a brief explanation of why it was classified this way\n",
    "4. Return a JSON object with one key named \"events\", formatted as follows:\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"events\": [\n",
    "    {{\n",
    "      \"type\": \"scene\",\n",
    "      \"text\": \"John entered the room and picked up the phone...\",\n",
    "      \"reason\": \"Continuous action in same room, same character, no time break.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"type\": \"none\",\n",
    "      \"text\": \"It had been three years since the war...\",\n",
    "      \"reason\": \"Expository flashback without active characters or events.\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Return only the JSON.\n",
    "\n",
    "STORY:\n",
    "\\\"\\\"\\\"{story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "NARRATIVE_SCENE_EXTRACTOR = extraction.ExtractionTemplate(\n",
    "    name=\"narrative_scene_extractor\",\n",
    "    system_template=NARRATIVE_SCENE_SYSTEM_PROMPT,\n",
    "    user_template=NARRATIVE_SCENE_USER_PROMPT,\n",
    ")\n",
    "\n",
    "def extract_narrative_scenes(\n",
    "        story_text: str,        \n",
    "        model_name: str = \"gpt-4o\",\n",
    "        temperature: float = 0.2,\n",
    "        template: Callable = NARRATIVE_SCENE_EXTRACTOR,\n",
    "    ) -> extraction.ExtractionResult:\n",
    "    \"\"\"\n",
    "    Extract narrative scenes from a story using the specified model.\n",
    "    \n",
    "    Args:\n",
    "        story_text (str): The text of the story to analyze.\n",
    "        model_name (str): The name of the OpenAI model to use for extraction.\n",
    "    \n",
    "    Returns:\n",
    "        extraction.ExtractionResult: The result of the extraction, including parsed output and any errors.\n",
    "    \"\"\"\n",
    "    return extraction.extract_from_story(\n",
    "        story_text,\n",
    "        template=template,\n",
    "        client=client,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the new version is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " [{'type': 'none',\n",
       "   'text': 'Of all the problems which have been submitted to my friend, Mr. Sherlock Holmes, for solution during the years of our intimacy, there were only two which I was the means of introducing to his notice—that of Mr. Hatherley’s thumb, and that of Colonel Warburton’s madness.',\n",
       "   'reason': 'Introduction and exposition, no active characters or events.'},\n",
       "  {'type': 'scene',\n",
       "   'text': 'It was in the summer of ’89, not long after my marriage, that the events occurred which I am now about to summarise.',\n",
       "   'reason': 'Introduction of time setting and events about to be summarized.'},\n",
       "  {'type': 'scene',\n",
       "   'text': 'One morning, at a little before seven o’clock, I was awakened by the maid tapping at the door to announce that two men had come from Paddington and were waiting in the consulting-room.',\n",
       "   'reason': 'Introduction of a new event with characters in a specific location.'},\n",
       "  {'type': 'scene',\n",
       "   'text': 'I entered my consulting-room and found a gentleman seated by the table.',\n",
       "   'reason': 'Continuation of the previous event with the same characters in the same location.'},\n",
       "  {'type': 'scene',\n",
       "   'text': 'Sherlock Holmes was, as I expected, lounging about his sitting-room in his dressing-gown, reading the agony column of The Times and smoking his before-breakfast pipe, which was composed of all the plugs and dottles left from his smokes of the day before, all carefully dried and collected on the corner of the mantelpiece.',\n",
       "   'reason': 'Introduction of Sherlock Holmes in a specific location and action.'}])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_scene_gpt_35_turbo = extract_narrative_scenes(example_story.body, model_name=\"gpt-3.5-turbo\")\n",
    "len(narrative_scene_gpt_35_turbo.extracted_output), narrative_scene_gpt_35_turbo.extracted_output[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this cell takes roughly 2-3 minutes and is an expensive GPT 4.0 call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,\n",
       " [{'type': 'none',\n",
       "   'text': 'Of all the problems\\nwhich have been submitted to my friend, Mr. Sherlock Holmes, for solution\\nduring the years of our intimacy, there were only two which I was the means of\\nintroducing to his notice—that of Mr. Hatherley’s thumb, and that\\nof Colonel Warburton’s madness. Of these the latter may have afforded a\\nfiner field for an acute and original observer, but the other was so strange in\\nits inception and so dramatic in its details that it may be the more worthy of\\nbeing placed upon record, even if it gave my friend fewer openings for those\\ndeductive methods of reasoning by which he achieved such remarkable results.\\nThe story has, I believe, been told more than once in the newspapers, but, like\\nall such narratives, its effect is much less striking when set forth en\\nbloc in a single half-column of print than when the facts slowly evolve\\nbefore your own eyes, and the mystery clears gradually away as each new\\ndiscovery furnishes a step which leads on to the complete truth. At the time\\nthe circumstances made a deep impression upon me, and the lapse of two years\\nhas hardly served to weaken the effect.',\n",
       "   'reason': 'Expository introduction providing background and context, without active characters or events.'},\n",
       "  {'type': 'none',\n",
       "   'text': 'It was in the summer of ’89, not long after my marriage, that the events\\noccurred which I am now about to summarise. I had returned to civil practice\\nand had finally abandoned Holmes in his Baker Street rooms, although I\\ncontinually visited him and occasionally even persuaded him to forgo his\\nBohemian habits so far as to come and visit us. My practice had steadily\\nincreased, and as I happened to live at no very great distance from Paddington\\nStation, I got a few patients from among the officials. One of these, whom I\\nhad cured of a painful and lingering disease, was never weary of advertising my\\nvirtues and of endeavouring to send me on every sufferer over whom he might\\nhave any influence.',\n",
       "   'reason': \"Expository passage providing background on the narrator's life and circumstances leading up to the main events.\"},\n",
       "  {'type': 'scene',\n",
       "   'text': 'One morning, at a little before seven o’clock, I was awakened by the maid\\ntapping at the door to announce that two men had come from Paddington and were\\nwaiting in the consulting-room. I dressed hurriedly, for I knew by experience\\nthat railway cases were seldom trivial, and hastened downstairs. As I\\ndescended, my old ally, the guard, came out of the room and closed the door\\ntightly behind him.\\n\\n“I’ve got him here,” he whispered, jerking his thumb over his\\nshoulder; “he’s all right.”\\n\\n“What is it, then?” I asked, for his manner suggested that it was\\nsome strange creature which he had caged up in my room.\\n\\n“It’s a new patient,” he whispered. “I thought\\nI’d bring him round myself; then he couldn’t slip away. There he\\nis, all safe and sound. I must go now, Doctor; I have my dooties, just the same\\nas you.” And off he went, this trusty tout, without even giving me time\\nto thank him.\\n\\nI entered my consulting-room and found a gentleman seated by the table. He was\\nquietly dressed in a suit of heather tweed with a soft cloth cap which he had\\nlaid down upon my books. Round one of his hands he had a handkerchief wrapped,\\nwhich was mottled all over with bloodstains. He was young, not more than\\nfive-and-twenty, I should say, with a strong, masculine face; but he was\\nexceedingly pale and gave me the impression of a man who was suffering from\\nsome strong agitation, which it took all his strength of mind to control.',\n",
       "   'reason': 'Continuous action in the consulting room with the introduction of a new character, Mr. Hatherley, and the beginning of the main narrative.'},\n",
       "  {'type': 'scene',\n",
       "   'text': '“I am sorry to knock you up so early, Doctor,” said he, “but\\nI have had a very serious accident during the night. I came in by train this\\nmorning, and on inquiring at Paddington as to where I might find a doctor, a\\nworthy fellow very kindly escorted me here. I gave the maid a card, but I see\\nthat she has left it upon the side-table.”\\n\\nI took it up and glanced at it. “Mr. Victor Hatherley, hydraulic\\nengineer, 16A, Victoria Street (3rd floor).” That was the name, style,\\nand abode of my morning visitor. “I regret that I have kept you\\nwaiting,” said I, sitting down in my library-chair. “You are fresh\\nfrom a night journey, I understand, which is in itself a monotonous\\noccupation.”\\n\\n“Oh, my night could not be called monotonous,” said he, and\\nlaughed. He laughed very heartily, with a high, ringing note, leaning back in\\nhis chair and shaking his sides. All my medical instincts rose up against that\\nlaugh.\\n\\n“Stop it!” I cried; “pull yourself together!” and I\\npoured out some water from a caraffe.\\n\\nIt was useless, however. He was off in one of those hysterical outbursts which\\ncome upon a strong nature when some great crisis is over and gone. Presently he\\ncame to himself once more, very weary and pale-looking.\\n\\n“I have been making a fool of myself,” he gasped.\\n\\n“Not at all. Drink this.” I dashed some brandy into the water, and\\nthe colour began to come back to his bloodless cheeks.\\n\\n“That’s better!” said he. “And now, Doctor, perhaps you\\nwould kindly attend to my thumb, or rather to the place where my thumb used to\\nbe.”\\n\\nHe unwound the handkerchief and held out his hand. It gave even my hardened\\nnerves a shudder to look at it. There were four protruding fingers and a horrid\\nred, spongy surface where the thumb should have been. It had been hacked or\\ntorn right out from the roots.\\n\\n“Good heavens!” I cried, “this is a terrible injury. It must\\nhave bled considerably.”\\n\\n“Yes, it did. I fainted when it was done, and I think that I must have\\nbeen senseless for a long time. When I came to I found that it was still\\nbleeding, so I tied one end of my handkerchief very tightly round the wrist and\\nbraced it up with a twig.”\\n\\n“Excellent! You should have been a surgeon.”\\n\\n“It is a question of hydraulics, you see, and came within my own\\nprovince.”\\n\\n“This has been done,” said I, examining the wound, “by a very\\nheavy and sharp instrument.”\\n\\n“A thing like a cleaver,” said he.\\n\\n“An accident, I presume?”\\n\\n“By no means.”\\n\\n“What! a murderous attack?”\\n\\n“Very murderous indeed.”\\n\\n“You horrify me.”\\n\\nI sponged the wound, cleaned it, dressed it, and finally covered it over with\\ncotton wadding and carbolised bandages. He lay back without wincing, though he\\nbit his lip from time to time.\\n\\n“How is that?” I asked when I had finished.\\n\\n“Capital! Between your brandy and your bandage, I feel a new man. I was\\nvery weak, but I have had a good deal to go through.”\\n\\n“Perhaps you had better not speak of the matter. It is evidently trying\\nto your nerves.”\\n\\n“Oh, no, not now. I shall have to tell my tale to the police; but,\\nbetween ourselves, if it were not for the convincing evidence of this wound of\\nmine, I should be surprised if they believed my statement, for it is a very\\nextraordinary one, and I have not much in the way of proof with which to back\\nit up; and, even if they believe me, the clues which I can give them are so\\nvague that it is a question whether justice will be done.”\\n\\n“Ha!” cried I, “if it is anything in the nature of a problem\\nwhich you desire to see solved, I should strongly recommend you to come to my\\nfriend, Mr. Sherlock Holmes, before you go to the official police.”\\n\\n“Oh, I have heard of that fellow,” answered my visitor, “and\\nI should be very glad if he would take the matter up, though of course I must\\nuse the official police as well. Would you give me an introduction to\\nhim?”\\n\\n“I’ll do better. I’ll take you round to him myself.”\\n\\n“I should be immensely obliged to you.”\\n\\n“We’ll call a cab and go together. We shall just be in time to have\\na little breakfast with him. Do you feel equal to it?”\\n\\n“Yes; I shall not feel easy until I have told my story.”\\n\\n“Then my servant will call a cab, and I shall be with you in an\\ninstant.” I rushed upstairs, explained the matter shortly to my wife, and\\nin five minutes was inside a hansom, driving with my new acquaintance to Baker\\nStreet.',\n",
       "   'reason': 'Continuous interaction between the narrator and Mr. Hatherley, involving the treatment of his injury and the decision to visit Sherlock Holmes, maintaining the same setting and characters.'},\n",
       "  {'type': 'scene',\n",
       "   'text': 'Sherlock Holmes was, as I expected, lounging about his sitting-room in his\\ndressing-gown, reading the agony column of The Times and smoking his\\nbefore-breakfast pipe, which was composed of all the plugs and dottles left\\nfrom his smokes of the day before, all carefully dried and collected on the\\ncorner of the mantelpiece. He received us in his quietly genial fashion,\\nordered fresh rashers and eggs, and joined us in a hearty meal. When it was\\nconcluded he settled our new acquaintance upon the sofa, placed a pillow\\nbeneath his head, and laid a glass of brandy and water within his reach.\\n\\n“It is easy to see that your experience has been no common one, Mr.\\nHatherley,” said he. “Pray, lie down there and make yourself\\nabsolutely at home. Tell us what you can, but stop when you are tired and keep\\nup your strength with a little stimulant.”\\n\\n“Thank you,” said my patient, “but I have felt another man\\nsince the doctor bandaged me, and I think that your breakfast has completed the\\ncure. I shall take up as little of your valuable time as possible, so I shall\\nstart at once upon my peculiar experiences.”\\n\\nHolmes sat in his big armchair with the weary, heavy-lidded expression which\\nveiled his keen and eager nature, while I sat opposite to him, and we listened\\nin silence to the strange story which our visitor detailed to us.',\n",
       "   'reason': 'Introduction of Sherlock Holmes and the setting of his sitting-room, where Mr. Hatherley begins to recount his story, maintaining continuity in time and characters.'}])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_scene_gpt_4o = extract_narrative_scenes(example_story.body, model_name=\"gpt-4o\")\n",
    "len(narrative_scene_gpt_4o.extracted_output), narrative_scene_gpt_4o.extracted_output[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk-Based Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max tokens divided by min scenes gives us a rough estimate of how many tokens are needed per scene.\n",
    "estimated_tokens_per_scene = float(comparison_df['tokens'].max() / comparison_df['scenes'].min())\n",
    "estimated_tokens_per_scene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_story = corpora.stories[0]\n",
    "story_text = example_story.body\n",
    "chunks = chunking.chunk_story(story_text, max_tokens=6000, overlap_tokens=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "print(f\"Chunked story into {len(chunks)} parts.\")\n",
    "for index, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {index} ({len(chunk.text)} chars):\")\n",
    "    print(chunk.text[:100] + \"...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking with overlap is likely smarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_story = corpora.stories[0]\n",
    "example_text = example_story.body\n",
    "\n",
    "example_chunks = chunking.chunk_story(example_text, max_tokens=6000, overlap_tokens=200, model_name=\"gpt-3.5-turbo\")\n",
    "chunking.display_chunks(example_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Scenes - LASTREVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SceneSpan:\n",
    "    chunk_index: int\n",
    "    relative_start: int\n",
    "    relative_end: int\n",
    "    scene_type: str\n",
    "    text: str\n",
    "    offset: int  # character offset in original story\n",
    "\n",
    "    def absolute_start(self) -> int:\n",
    "        return self.offset + self.relative_start\n",
    "\n",
    "    def absolute_end(self) -> int:\n",
    "        return self.offset + self.relative_end\n",
    "\n",
    "SCENE_SEQUEL_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that breaks down stories into structured narrative events.\n",
    "\n",
    "Each event must be labeled as:\n",
    "- \"scene\": a segment where a character pursues a goal, leading to success or failure.\n",
    "- \"sequel\": a segment where a character reacts to the outcome, reflects, and formulates a new plan.\n",
    "- \"none\": a segment that does not clearly fit into either category (e.g., exposition or transition).\n",
    "\n",
    "You MUST output a list of events as a JSON dictionary with one key: \"events\".\n",
    "\n",
    "Each event must include:\n",
    "- \"type\": one of \"scene\", \"sequel\", or \"none\"\n",
    "- \"reason\": a brief explanation of why you classified it this way\n",
    "- \"text\": the exact event text, copied from the story\n",
    "- \"start_char\": the starting character offset of the event in the original story\n",
    "- \"end_char\": the ending character offset (exclusive)\n",
    "\n",
    "Do NOT include any additional explanation or formatting.\n",
    "Only return valid JSON.\n",
    "\"\"\"\n",
    "\n",
    "SCENE_SEQUEL_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "I will give you a story in plain text.\n",
    "\n",
    "Please identify contiguous narrative segments that represent:\n",
    "- scenes (goal-driven attempts)\n",
    "- sequels (reflections after outcomes)\n",
    "- or neither (\"none\" for other material)\n",
    "\n",
    "For each segment, return a dictionary with:\n",
    "- \"type\": \"scene\", \"sequel\", or \"none\"\n",
    "- \"reason\": a brief explanation of why you classified it this way\n",
    "- \"text\": the exact span of text from the story\n",
    "- \"start_char\": starting character index of this span in the story\n",
    "- \"end_char\": ending character index (exclusive)\n",
    "\n",
    "Return a single JSON object with a key named \"events\" and a list of these entries.\n",
    "\n",
    "The output MUST be valid JSON and include ONLY the JSON, no explanation or comments.\n",
    "\n",
    "STORY:\n",
    "\\\"\\\"\\\"{story_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "def build_scene_sequel_prompt(story_text: str) -> list:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SCENE_SEQUEL_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": SCENE_SEQUEL_USER_PROMPT_TEMPLATE.format(story_text=story_text)}\n",
    "    ]\n",
    "\n",
    "\n",
    "def extract_scenes_and_sequels(story_text: str, model_name=\"gpt-3.5-turbo\") -> Dict:\n",
    "    messages = build_scene_sequel_prompt(story_text)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    raw_output = response.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        parsed_output = utils.extract_json(raw_output)\n",
    "        parsing_error = None\n",
    "    except json.JSONDecodeError as exc:\n",
    "        parsed_output = None\n",
    "        parsing_error = str(exc)\n",
    "\n",
    "    scene_spans: List[SceneSpan] = []\n",
    "    extraction_error = None\n",
    "\n",
    "    if isinstance(parsed_output, dict) and \"events\" in parsed_output:\n",
    "        for i, event in enumerate(parsed_output[\"events\"]):\n",
    "            scene_text = event.get(\"text\", \"\").strip()\n",
    "            scene_type = event.get(\"type\", \"scene\")\n",
    "\n",
    "            # Match scene_text in story_text to find offsets\n",
    "            match = re.search(re.escape(scene_text), story_text)\n",
    "            if match:\n",
    "                start_char = match.start()\n",
    "                end_char = match.end()\n",
    "            else:\n",
    "                start_char = None\n",
    "                end_char = None\n",
    "\n",
    "            scene_spans.append(SceneSpan(\n",
    "                chunk_index=0,  # Actual index will be set later by tail extraction logic\n",
    "                relative_start=0,  # Will be calculated by offset adjustment later\n",
    "                relative_end=0,\n",
    "                scene_type=scene_type,\n",
    "                text=scene_text,\n",
    "                offset=start_char if start_char is not None else 0  # fallback\n",
    "            ))\n",
    "\n",
    "            # Patch relative positions if match succeeded\n",
    "            if match:\n",
    "                scene_spans[-1].relative_start = 0  # initially 0, will be corrected in stitching\n",
    "                scene_spans[-1].relative_end = end_char - start_char\n",
    "\n",
    "    else:\n",
    "        scene_spans = []\n",
    "        extraction_error = \"Expected 'events' key in JSON response.\"\n",
    "\n",
    "    return {\n",
    "        \"story_text\": story_text,\n",
    "        \"model_name\": model_name,\n",
    "        \"messages\": messages,\n",
    "        \"response\": response,\n",
    "        \"raw_output\": raw_output,\n",
    "        \"parsed_output\": parsed_output,\n",
    "        \"extracted_output\": scene_spans,\n",
    "        \"parsing_error\": parsing_error,\n",
    "        \"extraction_error\": extraction_error,\n",
    "    }\n",
    "\n",
    "\n",
    "def span_is_complete(span: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Simple heuristic to determine if a scene span is complete.\n",
    "    \"\"\"\n",
    "    text = span.get(\"text\", \"\").strip()\n",
    "    return text.endswith(\".\") and not text.endswith(\"...\") and len(text) > 20\n",
    "\n",
    "def get_span_from_raw(\n",
    "    raw: Dict,\n",
    "    chunk_index: int,\n",
    "    chunk_input_text: str,\n",
    "    carryover_len: int,\n",
    "    chunk_offset: int\n",
    ") -> Optional[SceneSpan]:\n",
    "    \"\"\"\n",
    "    Convert a raw dict (LLM output) into a SceneSpan object.\n",
    "    Uses fallback matching if start_char and end_char are missing.\n",
    "    \"\"\"\n",
    "    scene_text = raw.get(\"text\", \"\").strip()\n",
    "    scene_type = raw.get(\"type\", \"scene\")\n",
    "\n",
    "    start_char = raw.get(\"start_char\")\n",
    "    end_char = raw.get(\"end_char\")\n",
    "\n",
    "    if start_char is None or end_char is None:\n",
    "        match = re.search(re.escape(scene_text), chunk_input_text)\n",
    "        if not match:\n",
    "            return None\n",
    "        start_char = match.start()\n",
    "        end_char = match.end()\n",
    "\n",
    "    adjusted_start = max(0, start_char - carryover_len)\n",
    "    adjusted_end = max(0, end_char - carryover_len)\n",
    "    print(f\"Processing span: {scene_text} (start: {start_char}, end: {end_char}) \"\n",
    "          f\"-> adjusted start: {adjusted_start}, adjusted end: {adjusted_end}\")\n",
    "    if adjusted_end <= 0:\n",
    "        print(f\"Skipping span entirely in carryover: {scene_text}\")\n",
    "        return None  # entirely in carryover, skip\n",
    "\n",
    "    return SceneSpan(\n",
    "        chunk_index=chunk_index,\n",
    "        relative_start=adjusted_start,\n",
    "        relative_end=adjusted_end,\n",
    "        scene_type=scene_type,\n",
    "        text=chunk_input_text[start_char:end_char],\n",
    "        offset=chunk_offset\n",
    "    )\n",
    "\n",
    "def extract_carryover_text(\n",
    "    raw_span: Dict,\n",
    "    chunk_input_text: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Extract tail of the final scene span for prepending to the next chunk.\n",
    "    Falls back on re-matching if no indices are given.\n",
    "    \"\"\"\n",
    "    last_text = raw_span.get(\"text\", \"\")\n",
    "    start = raw_span.get(\"start_char\")\n",
    "    end = raw_span.get(\"end_char\")\n",
    "\n",
    "    if start is not None and end is not None:\n",
    "        return chunk_input_text[start:end]\n",
    "\n",
    "    match = re.search(re.escape(last_text), chunk_input_text)\n",
    "    return chunk_input_text[match.start():match.end()] if match else \"\"\n",
    "\n",
    "\n",
    "def extract_scene_spans_with_tail(\n",
    "    chunks: List[Chunk],\n",
    "    model_name: str,\n",
    "    extract_fn: Callable[[str, str], Dict]\n",
    ") -> List[SceneSpan]:\n",
    "    stitched_spans: List[SceneSpan] = []\n",
    "    carryover_text = \"\"\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i + 1}/{len(chunks)}: {len(chunks[i].text)} chars\")\n",
    "        chunk_input_text = carryover_text + chunk.text\n",
    "        carryover_len = len(carryover_text)\n",
    "\n",
    "        # Call the model extractor\n",
    "        result = extract_fn(chunk_input_text, model_name=model_name)\n",
    "        raw_spans = result.get(\"extracted_output\", [])\n",
    "        print(f\"Extracted {len(raw_spans)} spans from chunk {i + 1}\")\n",
    "\n",
    "        # Try to convert all spans to SceneSpan\n",
    "        for raw in raw_spans:\n",
    "            span = get_span_from_raw(\n",
    "                raw,\n",
    "                chunk_index=i,\n",
    "                chunk_input_text=chunk_input_text,\n",
    "                carryover_len=carryover_len,\n",
    "                chunk_offset=chunk.start_char\n",
    "            )\n",
    "            if span:\n",
    "                stitched_spans.append(span)\n",
    "\n",
    "        # Setup carryover if final span is incomplete\n",
    "        if raw_spans and not span_is_complete(raw_spans[-1]):\n",
    "            carryover_text = extract_carryover_text(raw_spans[-1], chunk_input_text)\n",
    "        else:\n",
    "            carryover_text = \"\"\n",
    "\n",
    "    return stitched_spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_chunk = example_chunks[0]\n",
    "example_text = example_chunk.text\n",
    "example_prompt = build_scene_sequel_prompt(example_text)\n",
    "example_result = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=example_prompt,\n",
    "    temperature=0.2,\n",
    ")\n",
    "example_raw_output = example_result.choices[0].message.content\n",
    "example_parsed_output = utils.extract_json(example_raw_output)\n",
    "example_spans = example_parsed_output[\"events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_spans[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, length=72):\n",
    "    \"\"\"\n",
    "    Summarize the text to a specified length.\n",
    "    \"\"\"\n",
    "    if len(text) <= length:\n",
    "        return text\n",
    "    prefix = length // 2\n",
    "    return text[:prefix] + \"...\" + text[-(length - prefix):]\n",
    "\n",
    "\n",
    "for i, span in enumerate(example_spans):\n",
    "    # print(span)\n",
    "    print(f\"Span {i} type: {span.get('type')}, text: {summarize(span.get('text', ''))}\")\n",
    "    start_char = span.get(\"start_char\")\n",
    "    end_char = span.get(\"end_char\")\n",
    "    if start_char is not None and end_char is not None:\n",
    "        span_text = example_text[start_char:end_char]\n",
    "        print(f\" - start: {start_char}, end: {end_char}, text: {summarize(span_text)}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_chunk = example_chunks[0]\n",
    "extraction = extract_scenes_and_sequels(\n",
    "    example_chunk.text, model_name=\"gpt-3.5-turbo\")\n",
    "extraction['extracted_output'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_scene_spans_with_tail(\n",
    "    example_chunks,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    extract_fn=extract_scenes_and_sequels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks), chunks[0][:100], chunks[-1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {index} ({len(chunk)} chars):\")\n",
    "    print(chunk[:100] + \"...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCATS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
